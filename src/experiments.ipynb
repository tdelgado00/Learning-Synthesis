{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from prettytable import PrettyTable\n",
    "import pprint\n",
    "import pickle\n",
    "import json\n",
    "import os, sys\n",
    "os.chdir(\"../\")\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(value, label, color, ax, fontsize):\n",
    "    ax.text(5, value, label, {\"fontsize\": fontsize})\n",
    "    ax.axhline(y=value, color=color, linestyle=\"-\")\n",
    "\n",
    "def all_solved_instances(dfs):\n",
    "    instances = []\n",
    "    for n in range(1, 16):\n",
    "        for k in range(1, 16):\n",
    "            good = True\n",
    "            for df, cant in dfs:\n",
    "                if ((df[\"n\"] == n) & (df[\"k\"] == k)).sum() < cant:\n",
    "                    good = False\n",
    "                    break\n",
    "            if good:\n",
    "                instances.append((n, k))\n",
    "    return instances\n",
    "\n",
    "def add_rounded_idx(df, base):\n",
    "    df[\"rounded idx\"] = df[\"idx\"].apply(lambda idx : idx // base * base if idx < 100 else 100 - base)\n",
    "    df = df.loc[df[\"idx\"] <= (df[\"rounded idx\"].max()-1)*base]\n",
    "    return df\n",
    "\n",
    "def add_convolution(df, window_size):\n",
    "    df[\"mean transitions\"] = list(np.convolve(list(df[\"expanded transitions\"]), np.ones(window_size), mode='valid')/window_size)+\\\n",
    "                                [np.nan for _ in range(window_size-1)]\n",
    "    df[\"mean transitions / total\"] = df[\"mean transitions\"] / df[\"total transitions\"]\n",
    "    return df\n",
    "\n",
    "def fillna(df):\n",
    "    df[\"expanded transitions\"] = df[\"expanded transitions\"].fillna(df[\"expanded transitions\"].max()+10)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffced14",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "old_files = [\"base_features_2h\", \"ra_feature2opt_2h\", \"5mill_RA\", \"5mill_L\"]\n",
    "\n",
    "files = [(f, \"focused\") for f in [\"focused_1\", \"focused_2\", \"focused_4\", \"focused_5\", \"focused_6\", \"focused_7\", \"5mill_JE_NORA\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb37e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=10)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770908fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = {}\n",
    "df_ra_5s = {}\n",
    "df_random_5s = {}\n",
    "\n",
    "for problem in problems:\n",
    "    df_all[problem] = {}\n",
    "    for file, group in files:\n",
    "        if file in old_files:\n",
    "            dir = results_path(problem)+\"/\"+file+\"/\"+filename([problem, n, k])+\".csv\"\n",
    "        else:\n",
    "            dir = results_path(problem)+\"/\"+file+\"/generalization_all.csv\"\n",
    "        df = pd.read_csv(dir)\n",
    "        df = df.dropna(subset=[\"expanded transitions\"])\n",
    "        df[\"instance\"] = df.apply((lambda r: (r[\"problem\"], r[\"n\"], r[\"k\"])), axis=1)\n",
    "        df[\"total transitions\"] = df.apply(lambda r: monolithic_results[\"expanded transitions\", r[\"problem\"]][r[\"k\"]][r[\"n\"]], axis=1)\n",
    "        df[\"group\"] = group\n",
    "        df[\"training steps\"] = df[\"idx\"]*50000\n",
    "        df[\"expanded transitions / total\"] = df[\"expanded transitions\"] / df[\"total transitions\"]\n",
    "        df_all[problem][file] = df\n",
    "\n",
    "    df_ra_5s[problem] = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/RA_5s_15.csv\")\n",
    "    df_random_5s[problem] = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/random_5s.csv\")\n",
    "\n",
    "    for df in [df_ra_5s[problem], df_random_5s[problem]]:\n",
    "        df[\"instance\"] = df.apply(lambda r: (r[\"n\"], r[\"k\"]), axis=1)\n",
    "        df.dropna(subset=[\"expanded transitions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-fighter",
   "metadata": {},
   "source": [
    "## Comparing test transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2, k2 = 3, 3\n",
    "\n",
    "used_problems = [p for p in problems if p != \"CM\"] if n2 == 3 else problems\n",
    "\n",
    "f, axs = plt.subplots(1, len(problems), figsize=(5*len(problems), 6))\n",
    "\n",
    "for i in range(len(used_problems)):\n",
    "    problem = used_problems[i]\n",
    "\n",
    "    df = pd.concat([df_all[problem][file] for file, group in files], ignore_index=True)\n",
    "    df = df.loc[(df[\"n\"]==n2)&(df[\"k\"]==k2)]\n",
    "    df[\"reward\"] = -df[\"expanded transitions\"]\n",
    "\n",
    "    sns.lineplot(data=df, x=\"training steps\", y=\"reward\", ax=axs[i], hue=\"group\")\n",
    "    \n",
    "    ra = ra_results[\"expanded transitions\", problem][n2][k2]\n",
    "    plot_line(-ra, \"RA\", \"red\", axs[i], 15)\n",
    "    \n",
    "    random_min = min(random_results_small[(problems[i], n2, k2)])\n",
    "    random_mean = np.mean(random_results_small[(problems[i], n2, k2)])\n",
    "    \n",
    "    plot_line(-random_min, \"Random max\", \"green\", axs[i], 15)\n",
    "    plot_line(-random_mean, \"Random mean\", \"green\", axs[i], 15)\n",
    "    \n",
    "    axs[i].set_title(\" \".join([problem, str(n2), str(k2)]), fontdict={\"fontsize\": 18})\n",
    "\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "plt.legend(handles, labels, prop={'size': 15}, loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"experiments/figures/tmp.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-roads",
   "metadata": {},
   "source": [
    "## Plotting training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad769d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jpype\n",
    "if not jpype.isJVMStarted():\n",
    "    jpype.startJVM(classpath=['mtsa.jar'])\n",
    "#from MTSTools.ac.ic.doc.mtstools.model.operations.DCS.nonblocking import DCSForPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_data(problem, file, multiple):\n",
    "    with open(results_path(problem, file=file)+\"/training_data.pkl\", \"rb\") as f:\n",
    "        training_data, agent_params, env_params = pickle.load(f)    \n",
    "    df = pd.DataFrame(training_data)\n",
    "    df[\"idx\"] = df[\"training steps\"] // 10000\n",
    "    df[\"file\"] = file\n",
    "    df[\"problem\"] = problem\n",
    "    df[\"multiple\"] = multiple\n",
    "    if multiple:\n",
    "        instances = train_instances(problem)\n",
    "        df[\"n\"] = df.apply(lambda r: instances[int(r[\"idx\"]) % len(instances)][1], axis=1)\n",
    "        df[\"k\"] = df.apply(lambda r: instances[int(r[\"idx\"]) % len(instances)][2], axis=1)\n",
    "    else:\n",
    "        df[\"n\"] = 2\n",
    "        df[\"k\"] = 2\n",
    "    return df\n",
    "\n",
    "df_train = {}\n",
    "max_steps = 5000000\n",
    "\n",
    "used_files = [(f, \"focused\") for f in [\"focused_1\", \"focused_2\"]]\n",
    "used_problems = [\"AT\", \"BW\"]\n",
    "\n",
    "for problem in used_problems:\n",
    "    df_train[problem] = {}\n",
    "    for file, group in used_files:\n",
    "        multiple = \"RR\" in group\n",
    "        df = read_training_data(problem, file, multiple)\n",
    "        df = df.loc[df[\"training steps\"] <= max_steps]\n",
    "        df[\"group\"] = group\n",
    "        df_train[problem][file] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20806415",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = False\n",
    "for problem in used_problems:\n",
    "    for file, group in used_files:\n",
    "        df = df_train[problem][file]\n",
    "        df[\"total transitions\"] = df.apply(lambda r: monolithic_results[\"expanded transitions\", r[\"problem\"]][r[\"k\"]][r[\"n\"]], axis=1)\n",
    "        window_size = 100\n",
    "        \n",
    "        if normalized:\n",
    "            df['norm transitions'] = df.groupby('total transitions')[\"expanded transitions\"].apply(lambda x: (x - x.mean()) / x.std())\n",
    "            df[\"mean transitions\"] = list(np.convolve(list(df[\"norm transitions\"]), np.ones(window_size), mode='valid')/window_size)+[np.nan for _ in range(window_size-1)]\n",
    "        else:\n",
    "            df[\"mean transitions\"] = list(np.convolve(list(df[\"expanded transitions\"]), np.ones(window_size), mode='valid')/window_size)+[np.nan for _ in range(window_size-1)]\n",
    "        base = 10000\n",
    "        df[\"training steps\"] = df[\"training steps\"] // base * base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0213b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ra_and_random(files, problem, n, k, ax):\n",
    "    ra = ra_results[\"expanded transitions\", problem][n][k]\n",
    "    random_min = min(random_results_small[(problem, n, k)])\n",
    "    random_mean = np.mean(random_results_small[(problem, n, k)])\n",
    "    plot_line(-ra, \"RA\", \"red\", ax, 15)\n",
    "    plot_line(-random_min, \"Random max\", \"green\", ax, 15)\n",
    "    plot_line(-random_mean, \"Random mean\", \"green\", ax, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, len(used_problems), figsize=(5*len(used_problems), 6))\n",
    "\n",
    "for i in range(len(used_problems)):\n",
    "    problem = used_problems[i]\n",
    "    df = pd.concat([df_train[problem][f] for f, group in used_files], ignore_index=True)\n",
    "    df[\"reward\"] = -df[\"mean transitions\"]\n",
    "    \n",
    "    print(\"Plotting\", problem)\n",
    "    sns.lineplot(data=df, x=\"training steps\", y=\"reward\", ax=axs[i], hue=\"group\", ci=\"sd\", alpha=0.6)\n",
    "    \n",
    "    plot_ra_and_random(files, problems[i], 2, 2, axs[i])\n",
    "    \n",
    "    axs[i].get_legend().remove()\n",
    "    #if i != 0:\n",
    "    #    axs[i].get_yaxis().set_visible(False)\n",
    "    axs[i].set_title(problems[i], fontdict={\"fontsize\": 18})\n",
    "\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "plt.legend(handles, labels, prop={'size': 15}, loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"experiments/figures/tmp.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-school",
   "metadata": {},
   "source": [
    "## Plot solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_solved(problem, file, group):\n",
    "    df = df_all[problem][file]\n",
    "        \n",
    "    df_solved = []\n",
    "    for x, cant in dict(df[\"idx\"].value_counts()).items():\n",
    "        df_solved.append({\"idx\": x, \"solved\": cant})\n",
    "    df_solved = pd.DataFrame(df_solved)\n",
    "    df_solved.sort_values(by=\"idx\", inplace=True)\n",
    "\n",
    "    df_solved[\"file\"] = file\n",
    "    df_solved[\"group\"] = group\n",
    "    \n",
    "    window_size = 10\n",
    "    df_solved[\"max solved\"] = df_solved[\"solved\"].cummax()\n",
    "    df_solved[\"mean solved\"] = list(np.convolve(list(df_solved[\"solved\"]), np.ones(window_size), mode='valid')/window_size)+\\\n",
    "                                [np.nan for _ in range(window_size-1)]\n",
    "    return df_solved\n",
    "\n",
    "used_problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "used_files = files\n",
    "\n",
    "df_solved = {p: pd.concat([get_df_solved(p, f, g) for f, g in files], ignore_index=True) for p in used_problems}\n",
    "solved_ra = {p: len(list(df_ra_5s[p][\"expanded transitions\"].dropna())) for p in used_problems}\n",
    "solved_random = {p: len(list(df_random_5s[p][\"expanded transitions\"].dropna())) / 20 for p in used_problems}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644bc7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, len(used_problems), figsize=(5*len(used_problems), 6))\n",
    "\n",
    "for i in range(len(used_problems)):\n",
    "    problem = used_problems[i]\n",
    "    \n",
    "    plot_line(solved_ra[problem], \"RA\", \"red\", axs[i], 15)\n",
    "    plot_line(solved_random[problem], \"Random\", \"green\", axs[i], 15)\n",
    "    \n",
    "    sns.lineplot(data=df_solved[problem], x=\"idx\", y=\"solved\", ax=axs[i], hue=\"group\")\n",
    "\n",
    "    axs[i].set_title(problem)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig(\"experiments/figures/tmp.jpg\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2637352d",
   "metadata": {},
   "source": [
    "## Plot mean transitions generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_reward_df(problem, file, group, instances):\n",
    "    instances = [(problem, n, k) for n, k in instances]\n",
    "    df = df_all[problem][file]\n",
    "    dfl = df.loc[df[\"instance\"].isin(instances)]\n",
    "\n",
    "    df = pd.DataFrame([{\"idx\": cidx, \"reward\": -dfg[\"expanded transitions\"].sum()} for cidx, dfg in dfl.groupby(\"idx\")])\n",
    "    df.sort_values(by=\"idx\", inplace=True)\n",
    "    df[\"file\"] = file\n",
    "    df[\"group\"] = group\n",
    "\n",
    "    window_size = 10\n",
    "    df[\"min reward\"] = df[\"reward\"].cummax()\n",
    "    df[\"mean reward\"] = list(np.convolve(list(df[\"reward\"]), np.ones(window_size), mode='valid')/window_size)+[np.nan for _ in range(window_size-1)]\n",
    "    return df\n",
    "\n",
    "used_problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "used_files = files\n",
    "\n",
    "instances, df_ra, df_random, df_agent = {}, {}, {}, {}\n",
    "for p in used_problems:\n",
    "    instances[p] = all_solved_instances([(df_all[p][f], 100) for f,g in used_files]+\\\n",
    "                                        [(df_ra_5s[p], 1)]+\\\n",
    "                                        [(df_random_5s[p], 20)])\n",
    "    df_ra[p] = df_ra_5s[p].loc[df_ra_5s[p][\"instance\"].isin(instances[p])]\n",
    "    df_random[p] = df_random_5s[p].loc[df_random_5s[p][\"instance\"].isin(instances[p])]  \n",
    "    df_agent[p] = pd.concat([get_mean_reward_df(p, f, g, instances[p]) for f, g in files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, len(used_problems), figsize=(5*len(used_problems), 6))\n",
    "for i in range(len(used_problems)):\n",
    "    problem = used_problems[i]\n",
    "    \n",
    "    plot_line(-df_ra[problem][\"expanded transitions\"].dropna().sum(), \"RA\", \"red\", axs[i], 15)\n",
    "    plot_line(-df_random[problem][\"expanded transitions\"].dropna().sum() / 20, \"Random\", \"green\", axs[i], 15)\n",
    "    \n",
    "    sns.lineplot(data=df_agent[problem], x=\"idx\", y=\"reward\", ax=axs[i], hue=\"group\")\n",
    "    axs[i].set_title(problem)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig(\"experiments/figures/tmp.jpg\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-maryland",
   "metadata": {},
   "source": [
    "## 15 15 Solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "grey = \"#d0e1d4\"\n",
    "red = \"#ed6a5a\"\n",
    "blue = \"#008bf8\"\n",
    "green = \"#08a045\"\n",
    "green1 = \"#adc178\"\n",
    "green2 = \"#045c27\"\n",
    "\n",
    "def get_comp_solved_df(agent, ra):\n",
    "    only_ra = ((agent == float(\"inf\")) & (ra != float(\"inf\")))\n",
    "    only_agent = ((agent != float(\"inf\")) & (ra == float(\"inf\")))\n",
    "    both = ((agent != float(\"inf\")) & (ra != float(\"inf\")))\n",
    "    \n",
    "    return only_ra*1 + only_agent*2 + both*(3*(agent > ra) + 4*(agent == ra) + 5*(agent < ra))\n",
    "\n",
    "df1 = lambda problem: get_df_agent(problem, \"3stepRRu/all.csv\")\n",
    "df2 = lambda problem: get_df_comp(problem, random_results)\n",
    "\n",
    "used_problems = [\"AT\", \"BW\"]\n",
    "\n",
    "f, axs = plt.subplots(1, len(used_problems), figsize=(5*len(used_problems), 6))\n",
    "for i in range(len(used_problems)):\n",
    "    problem = used_problems[i]\n",
    "    df1p = df1(problem)\n",
    "    df2p = df2(problem)\n",
    "    sns.heatmap(data=get_comp_solved_df(df1(problem), df2(problem)), cmap=[grey, red, blue, green, green1, green2], vmin=0, vmax=5, ax=axs[i], cbar=False)\n",
    "    \n",
    "    print(problem, len(train_instances(problem)))\n",
    "    for problem, n, k in train_instances(problem):\n",
    "        axs[i].text(k - 0.5, n - 0.5, \"X\",\n",
    "                 horizontalalignment='center',\n",
    "                 verticalalignment='center',\n",
    "                 )\n",
    "    \n",
    "    axs[i].invert_yaxis()\n",
    "    axs[i].set_title(problem, fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"experiments/figures/NORA/focused_5_vs_RA.jpg\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-camel",
   "metadata": {},
   "source": [
    "## 15 15 transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = -3\n",
    "vmax = 3\n",
    "\n",
    "def best_transitions_agent(df_all):\n",
    "    instances = all_solved_instances([df_all])\n",
    "    \n",
    "    df_all[\"instance\"] = df_all.apply(lambda r: (r[\"n\"], r[\"k\"]), axis=1)\n",
    "    df_all = df_all.loc[df_all[\"instance\"].isin(instances)]\n",
    "    return min([(dfg[\"expanded transitions\"].sum(), cidx) for cidx, dfg in df_all.groupby(\"idx\")])[1]\n",
    "\n",
    "def df_agent_5s(problem, file):\n",
    "    df_all = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/\"+file+\"/generalization_all.csv\")\n",
    "    df_all[\"file\"] = file\n",
    "    df_all = df_all.dropna(subset=[\"expanded transitions\"])\n",
    "    idx = best_transitions_agent(df_all)\n",
    "    print(problem)\n",
    "    print(idx)\n",
    "    print(best_generalization_agent(problem, file))\n",
    "    df_agent = df_all.loc[df_all[\"idx\"] == idx]\n",
    "    df_agent = fill_df(df_agent, 15)\n",
    "    return df_agent.pivot(\"n\", \"k\", \"expanded transitions\")\n",
    "\n",
    "def get_heatmap_value(a, r):\n",
    "    if r == float(\"inf\") and np.all([ai == float(\"inf\") for ai in a]):\n",
    "        return np.nan\n",
    "    elif r == float(\"inf\"): # agent solved at least once and ra didnt\n",
    "        return vmin\n",
    "    elif not np.any([ai == float(\"inf\") for ai in a]): # both always solved\n",
    "        return np.mean([ai / r for ai in a])\n",
    "    elif np.all([ai == float(\"inf\") for ai in a]): \n",
    "        return vmax # agent never solved and ra solved\n",
    "    else: # agent solved sometimes and ra solved\n",
    "        return np.mean([np.log2(ai / r) for ai in a if ai != float(\"inf\")])\n",
    "\n",
    "def get_heatmap_value_only_solved(a, r):\n",
    "    if r == float(\"inf\") or np.any([ai == float(\"inf\") for ai in a]):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return np.mean([np.log2(ai / r) for ai in a])\n",
    "    \n",
    "def get_df(agent_dfs, ra):\n",
    "    m = np.zeros(shape=(15, 15))\n",
    "    for n in range(15):\n",
    "        for k in range(15):\n",
    "            r = ra[k+1][n+1]\n",
    "            a = [df[k+1][n+1] for df in agent_dfs]\n",
    "            m[n, k] = get_heatmap_value_only_solved(a, r)\n",
    "    return m\n",
    "\n",
    "agent_files = [\"5mill_JE_NORA\", \"focused_1\", \"focused_2\", \"focused_4\",\n",
    "               \"focused_5\", \"focused_6\", \"focused_7\"]\n",
    "\n",
    "#agent_files = [\"5mill_RR10k_NORA\", \"multiple_1\", \"multiple_2\"]\n",
    "agent_files = [\"5mill_C\"]\n",
    "\n",
    "used_problems = [\"AT\", \"BW\", \"DP\", \"TL\"]\n",
    "\n",
    "f, axs = plt.subplots(1, len(used_problems), figsize=(5*len(used_problems), 6))\n",
    "for i in range(len(used_problems)):\n",
    "    problem = used_problems[i]\n",
    "    dfs_agent = [get_df_agent(problem, file+\"/all.csv\") for file in agent_files]\n",
    "    #dfs_agent = [df_agent_5s(problems[i], file) for file in agent_files]\n",
    "    #dfs_agent = [df_comp(problems[i], ra_results, metric=metric)]\n",
    "    #df_ra = df_comp(problems[i], ra_results, metric=metric)\n",
    "    #df_ra = df_comp(problems[i], random_results, metric=metric)\n",
    "    df_ra = get_df_agent(problem, \"5mill_RA/all.csv\")\n",
    "    data = get_df(dfs_agent, df_ra)\n",
    "    sns.heatmap(data=data, \n",
    "                cmap=\"coolwarm\", #sns.cm.rocket_r#[grey, red, blue, green, green1, green2], \n",
    "                annot=True, annot_kws={\"size\":6},\n",
    "                ax=axs[i], cbar=True, vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    axs[i].invert_yaxis()\n",
    "    axs[i].set_title(problem, fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"experiments/figures/tmp.jpg\", dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-rubber",
   "metadata": {},
   "source": [
    "## Solved table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solved_metric(df, factor=1):\n",
    "    return len(df[\"expanded transitions\"].dropna()) / factor\n",
    "\n",
    "def mean_trans_metric(df, factor=1):\n",
    "    df[\"total\"] = df.apply(lambda r: monolithic_results[\"expanded transitions\", r[\"problem\"]][r[\"k\"]][r[\"n\"]], axis=1)\n",
    "    return (df[\"expanded transitions\"] / df[\"total\"]).mean()\n",
    "\n",
    "multiple = ([\"5mill_RR10k_NORA\", \"multiple_1\", \"multiple_2\"], \"multiple\")\n",
    "focused = ([\"5mill_JE_NORA\", \"focused_1\", \"focused_2\", \"focused_3\", \"focused_4\", \"focused_5\", \"focused_6\", \"focused_7\"], \"focused\")\n",
    "\n",
    "filegroups = [focused]\n",
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "\n",
    "approaches = [\"focused\", \"RA\", \"random\"]\n",
    "timeout = \"10m\"\n",
    "\n",
    "metric = solved_metric\n",
    "results = {problem: {ap: [] for ap in approaches} for problem in problems+[\"all\", \"all (AT, BW, DP, TA)\"]}\n",
    "for i in range(len(problems)):\n",
    "    for files, name in filegroups:\n",
    "        if name == \"multiple\" and problems[i] not in [\"AT\", \"TA\", \"BW\", \"DP\"]:\n",
    "            continue\n",
    "        for file in files:\n",
    "            if timeout == \"5s\":\n",
    "                df = pd.read_csv(\"experiments/results/\"+filename([problems[i], 2, 2])+\"/\"+file+\"/generalization_all.csv\")\n",
    "                best_idx = best_generalization_agent(problems[i], file)\n",
    "                df = df.loc[df[\"idx\"] == best_idx]\n",
    "            else:\n",
    "                df = pd.read_csv(\"experiments/results/\"+filename([problems[i], 2, 2])+\"/\"+file+\"/all.csv\")\n",
    "            results[problems[i]][name].append(metric(df))\n",
    "    \n",
    "    file_random = \"random_5s\" if timeout == \"5s\" else \"all_random\"\n",
    "    random_n = 20 if timeout == \"5s\" else 1\n",
    "    df_random = pd.read_csv(\"experiments/results/\"+filename([problems[i], 2, 2])+\"/\"+file_random+\".csv\")\n",
    "    results[problems[i]][\"random\"].append(metric(df_random, factor=random_n))\n",
    "    \n",
    "    file_ra = \"RA_5s_15\" if timeout == \"5s\" else \"all_ra_afterfix_15\"\n",
    "    df_ra = pd.read_csv(\"experiments/results/\"+filename([problems[i], 2, 2])+\"/\"+file_ra+\".csv\")\n",
    "    results[problems[i]][\"RA\"].append(metric(df_ra))\n",
    "\n",
    "for approach in approaches:\n",
    "    n = len(results[\"AT\"][approach])\n",
    "    if approach != \"multiple\":\n",
    "        results[\"all\"][approach] = [0 for j in range(n)]\n",
    "        for j in range(n):\n",
    "            for problem in problems:\n",
    "                results[\"all\"][approach][j] += results[problem][approach][j]\n",
    "    \n",
    "            \n",
    "    results[\"all (AT, BW, DP, TA)\"][approach] = [0 for j in range(n)]\n",
    "    for j in range(n):\n",
    "        for problem in [\"AT\", \"BW\", \"DP\", \"TA\"]:\n",
    "            results[\"all (AT, BW, DP, TA)\"][approach][j] += results[problem][approach][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp, wilcoxon\n",
    "\n",
    "for problem in problems+[\"all\"]:\n",
    "    print(problem)\n",
    "    random = results[problem][\"random\"][0]\n",
    "    ra = results[problem][\"RA\"][0] / random\n",
    "    agent = np.array(results[problem][\"focused\"]) / random\n",
    "    print(np.round(np.mean(agent), 2), np.round(ra, 2), ttest_1samp(agent-ra, 0, alternative=\"two-sided\").pvalue)\n",
    "    \n",
    "# p-valores con ttest:\n",
    "# AT significativamente mejor.\n",
    "# BW significativamente mejor.\n",
    "# CM significativemente peor.\n",
    "# DP significativemente peor.\n",
    "# TA iguales.\n",
    "# TL iguales.\n",
    "# General: iguales! (por muy poquito jaja, p=0.059)\n",
    "# Faltaría chequear la validez de este test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [{\"approach\": ap} for ap in approaches[:-1]]\n",
    "for problem in problems+[\"all\"]:#, \"all (AT, BW, DP, TA)\"]:\n",
    "    for j in range(len(approaches)-1):\n",
    "        r = results[problem][approaches[j]]\n",
    "        print(problem, approaches[j], r)\n",
    "        r = np.array(r) / results[problem][\"random\"][0]\n",
    "        mean = np.round(np.mean(r), 2)\n",
    "        std = np.round(np.std(r), 2)\n",
    "        if std > 0.0001:\n",
    "            rows[j][problem] = str(mean) + \" ± \" + str(std)\n",
    "        else:\n",
    "            rows[j][problem] = str(mean)\n",
    "\n",
    "dft = pd.DataFrame(rows)\n",
    "\n",
    "print(dft.to_latex(index=False, float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "for problem in problems:\n",
    "    ag = results[problem][\"focused\"]\n",
    "    ra = results[problem][\"focused\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-reason",
   "metadata": {},
   "source": [
    "## Solved instances vs expanded transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, k = 2, 2\n",
    "for problem in [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]:\n",
    "    print(problem)\n",
    "    file = \"focused_1\"\n",
    "\n",
    "    df_all = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/\"+file+\"/generalization_all.csv\")\n",
    "    df = []\n",
    "    for x, cant in dict(df_all[\"idx\"].value_counts()).items():\n",
    "        df.append({\"idx\": x, \"solved\": cant})\n",
    "    df = pd.DataFrame(df)\n",
    "    df.sort_values(by=\"idx\", inplace=True)\n",
    "\n",
    "    solved = list(df[\"solved\"])\n",
    "    trans = list(-df_all.loc[(df_all[\"n\"] == n) & (df_all[\"k\"] == k)][\"expanded transitions\"])\n",
    "\n",
    "    sns.regplot(x=trans, y=solved)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
