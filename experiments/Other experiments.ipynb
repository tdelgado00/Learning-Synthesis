{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "serious-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from prettytable import PrettyTable\n",
    "import pprint\n",
    "import pickle\n",
    "import json\n",
    "import os, sys\n",
    "os.chdir(\"../\")\n",
    "sys.path.append('src/')\n",
    "from util import *\n",
    "from train import train_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-causing",
   "metadata": {},
   "source": [
    "## Transitions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"base_features_2h\", \"ra_feature2opt_2h\", \"5mill_RA\", \"5mill_L\", \"5mill_C\", \"5mill_SL\", \"5mill_SL20\", \"5mill_JE\", \"5mill_JE20\", \"5mill_JEadam\"]\n",
    "old_files = [\"base_features_2h\", \"ra_feature2opt_2h\", \"5mill_RA\", \"5mill_L\"]\n",
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "for problem in problems:\n",
    "    x = PrettyTable()\n",
    "    x.field_names = [problem, \"min 2\", \"min 3\", \"last q\", \"ra 2\", \"ra 3\"]\n",
    "    for file in files:\n",
    "        if file in old_files:\n",
    "            df_2_2 = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/\"+file+\"/\"+filename([problem, 2, 2])+\".csv\")\n",
    "            df_3_3 = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/\"+file+\"/\"+filename([problem, 3, 3])+\".csv\")\n",
    "            df_q = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/\"+file+\"/q.csv\")\n",
    "        else:\n",
    "            df = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/\"+file+\"/generalization_all.csv\")\n",
    "            df_2_2 = fill_df(df.loc[(df[\"n\"]==2)&(df[\"k\"]==2)].copy(), 15)\n",
    "            df_3_3 = fill_df(df.loc[(df[\"n\"]==3)&(df[\"k\"]==3)].copy(), 15)\n",
    "            \n",
    "        min_2_2 = df_2_2[\"expanded transitions\"].min()\n",
    "        min_3_3 = df_3_3[\"expanded transitions\"].min()\n",
    "        \n",
    "        ra_2_2 = ra_results[\"expanded transitions\", problem][2][2]\n",
    "        ra_3_3 = ra_results[\"expanded transitions\", problem][3][3]\n",
    "        last_q = -df_q.iloc[-1][\"avg q\"]\n",
    "        x.add_row([file, min_2_2, min_3_3, last_q, ra_2_2, ra_3_3])\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-theme",
   "metadata": {},
   "source": [
    "## Plotting Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\"AT\", \"TA\", \"TL\", \"DP\", \"BW\", \"CM\"]\n",
    "for problem, n, k in [(x, 2, 2) for x in problems]:\n",
    "    df = pd.read_csv(\"experiments/results 25 mar/\"+filename([problem, n, k])+\"/10m_0.csv\")\n",
    "    df[\"avg q\"] = -df[\"avg q\"]\n",
    "    sns.lineplot(data=df, x=\"training time\", y=\"avg q\")\n",
    "    \n",
    "    plt.title(\" \".join([problem, str(n), str(k), \"q\"]))\n",
    "    \n",
    "    plt.savefig(\"experiments/figures/10m_0/q/\"+filename([problem, n, k])+\".jpg\", dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-sailing",
   "metadata": {},
   "source": [
    "## Correlation 2 2 vs 3 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\"AT\", \"BW\", \"DP\", \"TA\", \"TL\"]\n",
    "\n",
    "#files = [\"1mill\", \"T_1mill\", \"B_1mill\", \"TB_1mill\"]\n",
    "#files = [\"TB_5mill\", \"ra_feature2opt_2h\", \"base_features_2h\"]\n",
    "#files = [\"ra_feature2opt_2h\"]\n",
    "file = \"5mill_SL20\"\n",
    "\n",
    "for problem, n, k in [(x, 2, 2) for x in problems]:\n",
    "    \n",
    "    df = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+file+\"/generalization_all.csv\")\n",
    "    df = df.loc[(df[\"n\"] <= 5) & (df[\"k\"] <= 5)]\n",
    "    l = [{} for idx in range(101)]\n",
    "    for _, r in df.iterrows():\n",
    "        if not np.isnan(r[\"expanded transitions\"]):\n",
    "            l[r[\"idx\"]][r[\"n\"], r[\"k\"]] = r[\"expanded transitions\"]\n",
    "    i = 0\n",
    "    for x, cant in dict(df[\"idx\"].value_counts()).items():\n",
    "        l[i][\"solved\"] = cant\n",
    "        i+=1\n",
    "    #print(l)\n",
    "    for n in range(1, 5):\n",
    "        for k in range(1, 5):\n",
    "            others = [l[j][n, k] for j in range(101) if (n, k) in l[j].keys()]\n",
    "            if len(others) > 0:\n",
    "                for i in range(101):\n",
    "                    if (n, k) not in l[i].keys():\n",
    "                        l[i][n, k] = 2*np.max(others)\n",
    "            else:\n",
    "                print(n, k, problem, \"was not solved (in 5s)\")\n",
    "    #print([l[i][2, 2] for i in range(101)])\n",
    "    #print([l[i][3, 3] for i in range(101)])\n",
    "    sns.regplot(x=[l[i][2, 2] for i in range(101)], y=[l[i][3, 3] for i in range(101)])\n",
    "    plt.title(problem+\" correlation\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-navigator",
   "metadata": {},
   "source": [
    "## Generalization fixing n or k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = lambda problem: df_agent(problem, \"all_ra_afterfix_15.csv\")\n",
    "df1 = lambda problem: df_agent(problem, \"5mill_JE20/all.csv\")\n",
    "df2 = lambda problem: df_agent(problem, \"5mill_RR10k_D_N/all.csv\")\n",
    "df3 = lambda problem: df_agent(problem, \"5mill_RR10k_D/all.csv\")\n",
    "df4 = lambda problem: df_comp(problem, ra_results)\n",
    "df5 = lambda problem: df_comp(problem, random_results)\n",
    "\n",
    "dfs = [(df1, \"2 2\"), (df2, \"RR\"), (df3, \"RR nk\"), (df4, \"RA\"), (df5, \"random\")]\n",
    "\n",
    "problems = [\"AT\", \"TA\", \"BW\", \"DP\"]\n",
    "\n",
    "for n in range(1, 16):\n",
    "    print(\"N =\", n)\n",
    "    f, axs = plt.subplots(1, len(problems), figsize=(5*len(problems), 6))\n",
    "    for i in range(len(problems)):\n",
    "        for df, name in dfs:\n",
    "            sns.lineplot(x=np.arange(1, 16), y=df(problems[i]).iloc[n-1], ax=axs[i], marker=\"o\", label=name)\n",
    "        #axs[i].set_xlim((1, 5))\n",
    "        axs[i].set_title(problems[i], fontsize=30)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"experiments/figures/generalization/fixed n/\"+str(n)+\".jpg\", dpi=200)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-shock",
   "metadata": {},
   "source": [
    "## Heuristic time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comp_solved_df(df_agent_p, df_ra_p):\n",
    "    df1 = df_agent_p.fillna(float(\"inf\"))\n",
    "    df2 = df_ra_p.fillna(float(\"inf\"))\n",
    "    df1 = df1 != float(\"inf\")\n",
    "    df2 = df2 != float(\"inf\")\n",
    "    return 1*((df1 == df2) & df1) + 2*(df2 > df1) + 3*(df1 > df2)\n",
    "\n",
    "problems = [\"AT\", \"TA\", \"BW\", \"TL\", \"DP\", \"CM\"]\n",
    "#problems = [\"AT\", \"AT\"]\n",
    "f, axs = plt.subplots(1, len(problems), figsize=(10*len(problems), 12))\n",
    "\n",
    "\n",
    "for i in range(len(problems)):\n",
    "    df_a = pd.read_csv(\"experiments/results/\"+filename([problems[i], 2, 2])+\"/5mill_JE20/all.csv\")\n",
    "    df_a = fill_df(df_a, 15)\n",
    "    df_a[\"heuristic time rel\"] = df_a[\"heuristic time(ms)\"] / df_a[\"synthesis time(ms)\"]\n",
    "    df_agent_p = df_a.pivot(\"n\", \"k\", \"heuristic time(ms)\")\n",
    "    sns.heatmap(data=df_agent_p, ax=axs[i], cmap=sns.cm.rocket_r, annot=True, annot_kws={\"size\":8})\n",
    "    axs[i].invert_yaxis()\n",
    "    axs[i].set_title(problems[i], fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"experiments/figures/heuristic_time_JE20.jpg\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-zoning",
   "metadata": {},
   "source": [
    "## Training and exploration complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = [\"ra_feature2_target\", \"ra_feature2_2h\"]\n",
    "\n",
    "problems = [\"AT\", \"TA\", \"TL\", \"DP\", \"BW\"]\n",
    "for problem, n, k in [(x, 2, 2) for x in problems]:\n",
    "    problem2, n2, k2 = problem, 2, 2\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        dfs.append(pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+file+\"/\"+filename([problem2, n2, k2])+\".csv\"))\n",
    "        dfs[-1][\"file\"] = file\n",
    "        print(dfs[-1][\"training steps\"].max())\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    sns.scatterplot(data=df, x=\"training time\", y=\"training steps\", hue = \"file\")\n",
    "    plt.title(\" \".join([problem, str(n), str(k)]))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\"AT\", \"TA\", \"BW\", \"TL\", \"DP\"]\n",
    "f, axs = plt.subplots(1, len(problems), figsize=(5*len(problems), 6))\n",
    "\n",
    "for i in range(len(problems)):\n",
    "    df_a = pd.read_csv(\"experiments/results 25 mar/\"+filename([problems[i], 2, 2])+\"/Agent15.csv\")\n",
    "    df_ra = pd.read_csv(\"experiments/results 25 mar/\"+filename([problems[i], 2, 2])+\"/RA15.csv\")\n",
    "    df_a[\"approach\"] = \"Agent\"\n",
    "    df_ra[\"approach\"] = \"RA\"\n",
    "    \n",
    "    sns.lineplot(data=pd.concat([df_a, df_ra], ignore_index=True), x=\"expanded transitions\", y=\"synthesis time(ms)\", ax=axs[i], hue=\"approach\")\n",
    "    axs[i].set_title(problems[i], fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"experiments/figures/overhead.jpg\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\"]#, \"TA\", \"TL\"]\n",
    "f, axs = plt.subplots(1, len(problems), figsize=(5*len(problems), 6))\n",
    "files = [\"5mill_JE20\", \"5mill_JE_NORA\"]\n",
    "for i in range(len(problems)):\n",
    "    df1 = pd.read_csv(\"experiments/results/\"+filename([problems[i], 2, 2])+\"/\"+files[0]+\"/all.csv\")\n",
    "    df2 = pd.read_csv(\"experiments/results/\"+filename([problems[i], 2, 2])+\"/\"+files[1]+\"/all.csv\")\n",
    "    df_ra = df = pd.read_csv(\"experiments/results/\" + filename([problems[i], 2, 2]) + \"/all_ra_afterfix_15.csv\")\n",
    "    df1[\"approach\"] = files[0]\n",
    "    df2[\"approach\"] = files[1]\n",
    "    df_ra[\"approach\"] = \"RA\"\n",
    "    \n",
    "    sns.lineplot(data=pd.concat([df1, df2, df_ra], ignore_index=True), x=\"expanded transitions\", y=\"synthesis time(ms)\", ax=axs[i], marker=\"o\", hue=\"approach\")\n",
    "    axs[i].set_title(problems[i], fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"experiments/figures/overhead.jpg\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-serbia",
   "metadata": {},
   "source": [
    "## Frontier sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "n, k = 2, 2\n",
    "ra_feature = False\n",
    "dfs = []\n",
    "for problem in problems:\n",
    "    if problem == \"CM\" and n == 3:\n",
    "        continue\n",
    "    mono = monolithic_results[\"expanded transitions\", problem][n][k]\n",
    "    print(mono)\n",
    "    df = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/frontiers\"+(\"RA\" if ra_feature else \"\")+\".csv\")\n",
    "    df[\"problem\"] = problem\n",
    "    print(df[\"frontier size\"].max())\n",
    "    df[\"rel frontier size\"] = df[\"frontier size\"] / mono\n",
    "    df[\"frontier size / expanded\"] = df[\"frontier size\"] / df[\"step\"].max()\n",
    "    df[\"rel step\"] = df[\"step\"] / df[\"step\"].max()\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "sns.lineplot(data=df, x=\"rel step\", y=\"frontier size\", hue=\"problem\", ci=None)\n",
    "plt.savefig(\"experiments/figures/frontiers/sin RA/\"+filename([n, k])+\".jpg\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem, n, k = \"TL\", 3, 3\n",
    "ra_feature = True\n",
    "mono = monolithic_results[\"expanded transitions\", problem][n][k]\n",
    "#print(mono)\n",
    "df = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/frontiers\"+(\"RA\" if ra_feature else \"\")+\".csv\")\n",
    "df[\"problem\"] = problem\n",
    "#print(df[\"frontier size\"].max())\n",
    "df[\"rel frontier size\"] = df[\"frontier size\"] / mono\n",
    "df[\"frontier size / expanded\"] = df[\"frontier size\"] / df[\"step\"].max()\n",
    "df[\"rel step\"] = df[\"step\"] / df[\"step\"].max()\n",
    "\n",
    "for ep in range(1, 6):\n",
    "    dfloc = df.loc[df[\"ep\"] == ep]\n",
    "    print(dfloc[\"frontier size\"].max(), dfloc[\"step\"].max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
