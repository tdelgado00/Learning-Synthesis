{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "postal-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from prettytable import PrettyTable\n",
    "import pprint\n",
    "import pickle\n",
    "import json\n",
    "import os, sys\n",
    "os.chdir(\"../\")\n",
    "sys.path.append('src/')\n",
    "from util import *\n",
    "from train import train_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-mandate",
   "metadata": {},
   "source": [
    "# Monolithic and RA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(value, label, color, ax, fontsize):\n",
    "    ax.text(5, value, label, {\"fontsize\": fontsize})\n",
    "    ax.axhline(y=value, color=color, linestyle=\"-\")\n",
    "    \n",
    "def process_df(df, window_size=30, base=20):\n",
    "    df[\"best transitions\"] = df[\"expanded transitions\"].cummin()\n",
    "    df[\"rounded idx\"] = df[\"idx\"].apply(lambda idx : idx // base * base if idx < 100 else 100 - base)\n",
    "    #df = df.loc[df[\"idx\"] <= (df[\"rounded idx\"].max()-1)*window_size]\n",
    "    if len(df) < 30:\n",
    "        window_size = 10\n",
    "    df[\"training steps\"] = df[\"idx\"]*50000\n",
    "    df[\"mean transitions\"] = list(np.convolve(list(df[\"expanded transitions\"]), np.ones(window_size), mode='valid')/window_size)+[np.nan for _ in range(window_size-1)]\n",
    "    df[\"expanded transitions\"] = df[\"expanded transitions\"].fillna(df[\"expanded transitions\"].max()+10)\n",
    "    df[\"instance\"] = df.apply((lambda r: (r[\"problem\"], r[\"n\"], r[\"k\"])), axis=1)\n",
    "    df[\"total transitions\"] = df.apply(lambda r: monolithic_results[\"expanded transitions\", r[\"problem\"]][r[\"k\"]][r[\"n\"]], axis=1)\n",
    "    df[\"expanded transitions / total\"] = df[\"expanded transitions\"] / df[\"total transitions\"]\n",
    "    df[\"mean transitions / total\"] = df[\"mean transitions\"] / df[\"total transitions\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-satellite",
   "metadata": {},
   "source": [
    "# Comparing transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=10)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=10) \n",
    "\n",
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "#problems = [\"AT\", \"BW\", \"DP\", \"TA\"]\n",
    "\n",
    "n2, k2 = 2, 2\n",
    "if n2 == 3:\n",
    "    problems = [p for p in problems if p != \"CM\"]\n",
    "\n",
    "files = [\"base_features_2h\", \"ra_feature2opt_2h\", \"5mill_RA\", \"5mill_L\", \"5mill_C\", \"5mill_SL20\", \"5mill_JE\", \"5mill_JE20\"]\n",
    "old_files = [\"base_features_2h\", \"ra_feature2opt_2h\", \"5mill_RA\", \"5mill_L\"]\n",
    "files = [\"5mill_RA\", \"5mill_L\", \"5mill_C\", \"5mill_SL20\", \"5mill_JE20\", \"RR\"]\n",
    "files = [\"5mill_JE20\", \"5mill_JE_D\", \"5mill_RR10k_D\", \"5mill_RR10k_D_N\", \"5mill_RR10k_N\"]\n",
    "files = [\"5mill_JE20\", \"5mill_JE_NORA\", \"5mill_RR10k_NORA\", \"5mill_RR10k_D_N\", \"5mill_RR10k_NORA_1\"]\n",
    "files = [\"focused_1\", \"multiple_1\", \"no_TB\"]\n",
    "\n",
    "f, axs = plt.subplots(1, len(problems), figsize=(5*len(problems), 6))\n",
    "\n",
    "for i in range(len(problems)):\n",
    "    problem = problems[i]\n",
    "    dfs = []\n",
    "    for n, k, file  in [(2, 2, f) for f in files]:\n",
    "        try:\n",
    "            if file in old_files:\n",
    "                df = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/\"+file+\"/\"+filename([problem, n2, k2])+\".csv\")\n",
    "            else:\n",
    "                df = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/\"+file+\"/generalization_all.csv\")\n",
    "                df = df.loc[(df[\"n\"]==n2)&(df[\"k\"]==k2)]\n",
    "            \n",
    "            df = process_df(df)\n",
    "            df[\"case\"] = filename([n, k, file])\n",
    "            dfs.append(df)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df[\"acc. reward (= -expanded transitions)\"] = -df[\"expanded transitions\"]\n",
    "    sns.lineplot(data=df, x=\"training steps\", y=\"acc. reward (= -expanded transitions)\", hue=\"case\", ax=axs[i], ci=None)\n",
    "    #axs[i].set_ylim((0, 1))\n",
    "    \n",
    "    ra = ra_results[\"expanded transitions\", problems[i]][n2][k2]\n",
    "    random_min = min(random_results_small[(problems[i], n2, k2)])\n",
    "    random_mean = np.mean(random_results_small[(problems[i], n2, k2)])\n",
    "    plot_line(-ra, \"RA\", \"red\", axs[i], 15)\n",
    "    plot_line(-random_min, \"Random max\", \"green\", axs[i], 15)\n",
    "    plot_line(-random_mean, \"Random mean\", \"green\", axs[i], 15)\n",
    "    if i != len(problems)-1:\n",
    "        axs[i].get_legend().remove()\n",
    "    axs[i].set_title(\" \".join([problem, str(n2), str(k2)]), fontdict={\"fontsize\": 18})\n",
    "\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "plt.legend(handles, labels, prop={'size': 15}, loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"experiments/figures/NORA/tmp.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-paintball",
   "metadata": {},
   "source": [
    "## Plotting training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10) \n",
    "\n",
    "def read_training_data(problem, file, multiple):\n",
    "    with open(\"experiments/results/\"+filename([problem, 2, 2])+\"/\"+file+\"/training_data.pkl\", \"rb\") as f:\n",
    "        training_data, agent_params, env_params = pickle.load(f)    \n",
    "    df = pd.DataFrame(training_data)\n",
    "    df[\"idx\"] = df[\"training steps\"] // 10000\n",
    "    df[\"case\"] = file\n",
    "    df[\"problem\"] = problem\n",
    "    if multiple:\n",
    "        instances = train_instances(problem)\n",
    "        df[\"n\"] = df.apply(lambda r: instances[int(r[\"idx\"]) % len(instances)][0], axis=1)\n",
    "        df[\"k\"] = df.apply(lambda r: instances[int(r[\"idx\"]) % len(instances)][1], axis=1)\n",
    "    else:\n",
    "        df[\"n\"] = 2\n",
    "        df[\"k\"] = 2\n",
    "        df[\"problem\"] = problem\n",
    "    return df\n",
    "\n",
    "files = [(\"focused_1\", False), (\"focused_2\", False), (\"multiple_1\", True), (\"multiple_2\", True)]\n",
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "\n",
    "f, axs = plt.subplots(1, len(problems), figsize=(5*len(problems), 6))\n",
    "\n",
    "for i in range(len(problems)):\n",
    "    dfs = []\n",
    "    for file, multiple in files:\n",
    "        try:\n",
    "            df = read_training_data(problems[i], file, multiple)\n",
    "            df = process_df(df, window_size=50)\n",
    "            df[\"multiple\"] = multiple\n",
    "            df['norm transitions'] = df.groupby('total transitions')[\"expanded transitions\"].apply(lambda x: (x - x.mean()) / x.std())\n",
    "            dfs.append(df)\n",
    "        except OSError as e:\n",
    "            print(\"Couldn't read\", file, \"for problem\", problems[i])\n",
    "        \n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    #print(list(df[\"total transitions\"]))\n",
    "    df[\"acc. reward (= -expanded transitions)\"] = -df[\"expanded transitions\"]\n",
    "    df[\"normalized acc. reward (= -normalized expanded transitions)\"] = -df[\"norm transitions\"]\n",
    "    sns.lineplot(data=df, x=\"training steps\", y=\"normalized acc. reward (= -normalized expanded transitions)\", hue=\"multiple\", ax=axs[i], alpha=0.6)\n",
    "    \n",
    "    mean = df.loc[~df[\"multiple\"]][\"expanded transitions\"].mean()\n",
    "    std = df.loc[~df[\"multiple\"]][\"expanded transitions\"].std()\n",
    "    \n",
    "    ra = (ra_results[\"expanded transitions\", problems[i]][2][2] - mean) / std\n",
    "    random_min = (min(random_results_small[(problems[i], 2, 2)]) - mean) / std\n",
    "    random_mean = (np.mean(random_results_small[(problems[i], 2, 2)]) - mean) / std\n",
    "    plot_line(-ra, \"RA\", \"red\", axs[i], 15)\n",
    "    plot_line(-random_min, \"Random max\", \"green\", axs[i], 15)\n",
    "    plot_line(-random_mean, \"Random mean\", \"green\", axs[i], 15)\n",
    "    if i != len(problems)-1:\n",
    "        axs[i].get_legend().remove()\n",
    "    #if i != 0:\n",
    "    #    axs[i].get_yaxis().set_visible(False)\n",
    "    axs[i].set_title(problems[i], fontdict={\"fontsize\": 18})\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "plt.legend(handles, labels, prop={'size': 15}, loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"experiments/figures/NORA/tmp.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-weight",
   "metadata": {},
   "source": [
    "## Plot solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "problems = [\"AT\", \"BW\", \"DP\", \"TA\"]\n",
    "f, axs = plt.subplots(1, len(problems), figsize=(5*len(problems), 6))\n",
    "\n",
    "files1 = [\"5mill_C\", \"5mill_SL\", \"5mill_SL20\", \"5mill_JE\", \"5mill_JE20\"]\n",
    "files2 = [\"5mill_JE20\", \"5mill_RR10k_D\", \"RR\", \"5mill_RR10k_D_N\", \"5mill_RR10k_N\"]\n",
    "files3 = [\"5mill_JE20\", \"5mill_JE_NORA\", \"5mill_RR10k_NORA\", \"5mill_RR10k_D_N\", \"5mill_RR10k_NORA_1\"]\n",
    "files4 = [\"5mill_RR10k_NORA\", \"5mill_RR10k_NORA_1\"]\n",
    "files = [\"focused_1\", \"focused_2\", \"multiple_1\", \"multiple_2\", \"no_TB\"]#, \"5mill_JE20\", \"5mill_RR10k_D_N\"]\n",
    "#files = {f for f in files1+files2+files3+files4+files5}\n",
    "\n",
    "\n",
    "metric = \"mean solved\"\n",
    "n, k = 2, 2\n",
    "for i in range(len(problems)):\n",
    "    problem = problems[i]\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            df_all = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+file+\"/generalization_all.csv\")\n",
    "            df = []\n",
    "            for x, cant in dict(df_all[\"idx\"].value_counts()).items():\n",
    "                df.append({\"idx\": x, \"solved\": cant})\n",
    "            df = pd.DataFrame(df)\n",
    "            df.sort_values(by=\"idx\", inplace=True)\n",
    "            df[\"file\"] = file\n",
    "            window_size = 10\n",
    "            df[\"mean solved\"] = list(np.convolve(list(df[\"solved\"]), np.ones(window_size), mode='valid')/window_size)+[np.nan for _ in range(window_size-1)]\n",
    "            dfs.append(df)\n",
    "        except BaseException as e:\n",
    "            print(\"Couldn't read\", file)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    print(problem)\n",
    "    for file in files:\n",
    "        if len(df.loc[df[\"file\"]==file]) > 0:\n",
    "            print(file, df.loc[df[\"file\"]==file][\"solved\"].argmax())\n",
    "    \n",
    "    sns.lineplot(data=df, x=\"idx\", y=metric, ax=axs[i], hue=\"file\")\n",
    "    axs[i].set_title(problem)\n",
    "    #axs[i].set_ylim((0, 100))\n",
    "plt.tight_layout()\n",
    "    \n",
    "#plt.savefig(\"experiments/figures/NORA/\"+metric+\".jpg\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-alias",
   "metadata": {},
   "source": [
    "## 15 15 Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comp_solved_df(agent, ra):\n",
    "    only_ra = ((agent == float(\"inf\")) & (ra != float(\"inf\")))\n",
    "    only_agent = ((agent != float(\"inf\")) & (ra == float(\"inf\")))\n",
    "    both = ((agent != float(\"inf\")) & (ra != float(\"inf\")))\n",
    "    \n",
    "    return only_ra*1 + only_agent*2 + both*(3*(agent > ra) + 4*(agent == ra) + 5*(agent < ra))\n",
    "\n",
    "metric = \"expanded transitions\"\n",
    "#df1 = lambda problem: df_agent(problem, \"all_ra_afterfix_15.csv\")\n",
    "#df1 = lambda problem: df_agent(problem, \"5mill_JE20/all.csv\")\n",
    "df1 = lambda problem: df_agent(problem, \"multiple_2/all.csv\", metric=metric)\n",
    "#df1 = lambda problem: df_agent(problem, \"multiple_all/all.csv\", metric=metric)\n",
    "#df1 = lambda problem: df_agent(problem, \"5mill_RR10k_NORA/all.csv\", metric=metric)\n",
    "#df1 = lambda problem: df_agent(problem, \"RR/all.csv\")\n",
    "#df1 = lambda problem: df_agent(problem, \"all_e_15.csv\")\n",
    "#df1 = lambda problem: df_agent(problem, \"all_random1.csv\")\n",
    "#df1 = lambda problem: df_agent(problem, \"all_open_15.csv\")\n",
    "#df1 = lambda problem: df_comp(problem, ra_results)\n",
    "\n",
    "\n",
    "#df2 = lambda problem: df_agent(problem, \"all_ra_old_15_old.csv\")\n",
    "#df2 = lambda problem: df_agent(problem, \"RR/all.csv\")\n",
    "#df2 = lambda problem: df_agent(problem, \"RR/all.csv\", metric=metric)\n",
    "#df2 = lambda problem: df_agent(problem, \"focused_1/all.csv\", metric=metric)\n",
    "#df2 = lambda problem: df_agent(problem, \"5mill_JE_NORA/all.csv\", metric=metric)\n",
    "#df2 = lambda problem: df_agent(problem, \"5mill_RR10k_D_N/all.csv\", metric=metric)\n",
    "#df2 = lambda problem: df_agent(problem, \"focused_1/all.csv\", metric=metric)\n",
    "#df2 = lambda problem: df_agent(problem, \"5mill_RR10k_N/all.csv\")\n",
    "#df2 = lambda problem: df_agent(problem, \"all_random.csv\")\n",
    "#df2 = lambda problem: df_comp(problem, random_results)\n",
    "df2 = lambda problem: df_comp(problem, ra_results, metric=metric)\n",
    "#df2 = lambda problem: df_comp(problem, monolithic_results, metric=metric)\n",
    "\n",
    "#print(df1(\"DP\"))\n",
    "#print(df2(\"DP\"))\n",
    "\n",
    "problems = [\"AT\", \"TA\", \"BW\", \"TL\", \"DP\", \"CM\"]\n",
    "problems = [\"AT\", \"TA\", \"BW\", \"DP\"]\n",
    "f, axs = plt.subplots(1, len(problems), figsize=(5*len(problems), 6))\n",
    "s1 = []\n",
    "s2 = []\n",
    "df1w = []\n",
    "df2w = []\n",
    "for i in range(len(problems)):\n",
    "    \n",
    "    grey = \"#d0e1d4\"\n",
    "    red = \"#ed6a5a\"\n",
    "    blue = \"#008bf8\"\n",
    "    green = \"#08a045\"\n",
    "    green1 = \"#adc178\"\n",
    "    green2 = \"#045c27\"\n",
    "    df1p = df1(problems[i])\n",
    "    df2p = df2(problems[i])\n",
    "    s1.append(np.sum([df1p[n][k] != float(\"inf\") for n in range(1, 16) for k in range(1, 16)]))\n",
    "    s2.append(np.sum([df2p[n][k] != float(\"inf\") for n in range(1, 16) for k in range(1, 16)]))\n",
    "    df1w.append(np.sum([df1p[n][k] < df2p[n][k] for n in range(1, 16) for k in range(1, 16)]))\n",
    "    df2w.append(np.sum([df2p[n][k] < df1p[n][k] for n in range(1, 16) for k in range(1, 16)]))\n",
    "    sns.heatmap(data=get_comp_solved_df(df1(problems[i]), df2(problems[i])), cmap=[grey, red, blue, green, green1, green2], vmin=0, vmax=5, ax=axs[i], cbar=False)\n",
    "    \n",
    "    print(problems[i], len(train_instances(problems[i])))\n",
    "    for n, k in train_instances(problems[i]):\n",
    "        axs[i].text(k - 0.5, n - 0.5, \"X\",\n",
    "                 horizontalalignment='center',\n",
    "                 verticalalignment='center',\n",
    "                 )\n",
    "    \n",
    "    axs[i].invert_yaxis()\n",
    "    axs[i].set_title(problems[i], fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"experiments/figures/NORA/training_instances.jpg\", dpi=200)\n",
    "plt.show()\n",
    "print(s1, np.sum(s1))\n",
    "print(s2, np.sum(s2))\n",
    "print(df1w, np.sum(df1w))\n",
    "print(df2w, np.sum(df2w))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-corporation",
   "metadata": {},
   "source": [
    "## Solved table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_table_to_rows(df):\n",
    "    newdf = []\n",
    "    for n in range(1, 16):\n",
    "        for k in range(1, 16):\n",
    "            newdf.append({\"expanded transitions\": df[k][n], \"k\": k, \"n\": n})\n",
    "    return pd.DataFrame(newdf)\n",
    "metric = \"expanded transitions\"\n",
    "filegroups = [([\"5mill_RR10k_NORA\", \"multiple_1\", \"multiple_2\"], \"multiple\"), ([\"5mill_JE20\", \"focused_1\", \"focused_2\"], \"focused\"), ([\"no_TB\"], \"no TB\")]\n",
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "\n",
    "dfss = []\n",
    "for i in range(len(problems)):\n",
    "    dfs = []\n",
    "    for files, name in filegroups:\n",
    "        for file in files:\n",
    "            try:\n",
    "                df = pivot_table_to_rows(df_agent(problems[i], file+\"/all.csv\", metric=metric))\n",
    "                dfs.append(df)\n",
    "                dfs[-1][\"file\"] = file\n",
    "                dfs[-1][\"approach\"] = name\n",
    "            except:\n",
    "                pass\n",
    "    df_random = pivot_table_to_rows(df_comp(problems[i], random_results, metric=metric))\n",
    "    df_random[\"approach\"] = \"random\"\n",
    "    df_random[\"file\"] = \"only file\"\n",
    "    df_ra = pivot_table_to_rows(df_comp(problems[i], ra_results, metric=metric))\n",
    "    df_ra[\"approach\"] = \"RA\"\n",
    "    df_ra[\"file\"] = \"only file\"\n",
    "    dfss.append(pd.concat(dfs+[df_random, df_ra], ignore_index=True))\n",
    "    dfss[-1][\"problem\"] = problems[i]\n",
    "df = pd.concat(dfss, ignore_index=True)\n",
    "\n",
    "approaches = [\"focused\", \"multiple\", \"no TB\", \"RA\", \"random\"]\n",
    "rows = [{\"approach\": ap} for ap in approaches]\n",
    "\n",
    "print(approaches)\n",
    "for problem in problems:\n",
    "    dfp = df.loc[df[\"problem\"] == problem]\n",
    "    for j in range(len(approaches)):\n",
    "        #if approaches[j] in [\"random\", \"RA\"]:\n",
    "        #    print(approaches[j])\n",
    "        #    print(list(dfp.loc[(dfp[\"approach\"] == approaches[j])][\"expanded transitions\"]))\n",
    "        g = (dfp.loc[(dfp[\"approach\"] == approaches[j]) & (dfp[\"expanded transitions\"] != float(\"inf\"))])\n",
    "        #print(dict(g[\"file\"].value_counts()))\n",
    "        s = np.mean(list(dict(g[\"file\"].value_counts()).values()))\n",
    "        rows[j][problem] = s\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df[\"total\"] = df.apply(lambda row: np.sum([row[problem] for problem in problems]), axis=1)\n",
    "df[\"total (AT, BW, DP, TA)\"] = df.apply(lambda row: np.sum([row[problem] for problem in [\"AT\", \"BW\", \"DP\", \"TA\"]]), axis=1)\n",
    "\n",
    "print(df.to_latex(index=False, float_format=\"%.2f\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-jenny",
   "metadata": {},
   "source": [
    "## 15 15 Generalization average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_n_curve(df):\n",
    "    max_n = []\n",
    "    for k in range(1, 16):\n",
    "        max_n.append(np.sum(df[k] != float(\"inf\")))\n",
    "    return pd.DataFrame({\"k\": np.arange(1, 16), \"max n\": max_n})\n",
    "    \n",
    "\n",
    "metric = \"expanded transitions\"\n",
    "\n",
    "filegroups = [([\"5mill_RR10k_NORA\", \"multiple_1\"], \"multiple\"), ([\"5mill_JE20\", \"focused_1\"], \"focused\")]\n",
    "\n",
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "\n",
    "f, axs = plt.subplots(1, len(problems), figsize=(5*len(problems), 6))\n",
    "\n",
    "for i in range(len(problems)):\n",
    "    dfs = []\n",
    "    for files, name in filegroups:\n",
    "        for file in files:\n",
    "            try:\n",
    "                df = df_agent(problems[i], file+\"/all.csv\", metric=metric)\n",
    "                dfs.append(get_max_n_curve(df))\n",
    "                dfs[-1][\"file\"] = file\n",
    "                dfs[-1][\"approach\"] = name\n",
    "            except:\n",
    "                pass\n",
    "    df_random = get_max_n_curve(df_comp(problems[i], random_results, metric=metric))\n",
    "    df_random[\"approach\"] = \"random\"\n",
    "    df_ra = get_max_n_curve(df_comp(problems[i], ra_results, metric=metric))\n",
    "    df_ra[\"approach\"] = \"RA\"\n",
    "    \n",
    "    df = pd.concat(dfs+[df_ra, df_random], ignore_index=True)\n",
    "    \n",
    "    sns.lineplot(data=df, x=\"k\", y=\"max n\", hue=\"approach\", ax=axs[i], ci=None, marker=\"o\")\n",
    "    axs[i].set_ylim((0, 16))\n",
    "    axs[i].set_xlim((0, 16))\n",
    "    axs[i].set_title(problems[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"experiments/figures/NORA/NORA_vs_RA.jpg\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-bridal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "flying-diabetes",
   "metadata": {},
   "source": [
    "# Comparing avg Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "problems = [\"AT\", \"BW\", \"DP\", \"TA\"]\n",
    "\n",
    "files = [\"5mill_RA\", \"5mill_L\", \"5mill_C\", \"5mill_SL20\", \"5mill_JE20\", \"5mill_JE_NORA\"]\n",
    "#files = [\"5mill_JE20\", \"RR\", \"5mill_RR10k_D\", \"5mill_RR10k_N\", \"5mill_RR10k_D_N\"]\n",
    "files = [\"5mill_JE20\", \"5mill_JE_NORA\", \"focused_1\", \"multiple_1\", \"5mill_RR10k_NORA\", \"no_TB\"]\n",
    "\n",
    "f, axs = plt.subplots(1, len(problems), figsize=(5*len(problems), 6))\n",
    "\n",
    "for i in range(len(problems)):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        dfs.append(pd.read_csv(\"experiments/results/\"+filename([problems[i], n, k])+\"/\"+file+\"/q.csv\"))\n",
    "        dfs[-1][\"file\"] = file\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df[\"avg q\"] = -df[\"avg q\"]\n",
    "    sns.lineplot(data = df, x=\"training steps\", y=\"avg q\", hue=\"file\", ax=axs[i])\n",
    "    \n",
    "    axs[i].set_title(problems[i])\n",
    "#plt.savefig(\"experiments/figures/q.jpg\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-approach",
   "metadata": {},
   "source": [
    "# Analyzing models output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "a = 0\n",
    "def plot_q_and_pred(m, df_features, features, problem):\n",
    "    print(problem, m.rank_, m.intercept_)\n",
    "    print(m.coef_)\n",
    "    print(m.score(df_features[features], df_features[\"q\"]))\n",
    "    print(df_features[\"q\"].min(), df_features[\"q\"].max())\n",
    "    df_features[\"pred\"] = m.predict(df_features[features])\n",
    "    df_features[\"pred\"].plot(kind=\"hist\")\n",
    "    plt.title((\"pred\", problem))\n",
    "    plt.show()\n",
    "    plt.title(\"q\")\n",
    "    df_features[\"q\"].plot(kind=\"hist\")\n",
    "    plt.title((\"q\", problem))\n",
    "    plt.show()\n",
    "\n",
    "def plot_features(problem, n, k, dir):\n",
    "    df_features = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+dir+\"/best.csv\")\n",
    "    \n",
    "    features = feature_names(get_agent_info(agent_path(filename([problem, n, k]) + \"/\" + file, 0)), problem)\n",
    "    #print(features)\n",
    "    #m = LinearRegression()\n",
    "    #m.fit(df_features[features], df_features[\"q\"])\n",
    "    #plot_q_and_pred(m, df_features, features, problem)\n",
    "    \n",
    "    constant_filter = VarianceThreshold(threshold=0)\n",
    "    constant_filter.fit(df_features[features])\n",
    "    constant_columns = [column for column in df_features[features].columns if column not in df_features[features].columns[constant_filter.get_support()]]\n",
    "    print(\"Constant columns: \", constant_columns)\n",
    "    X = df_features[features].loc[:, constant_filter.get_support()]\n",
    "    #fvalues, pvalues = f_regression(X, df_features[\"q\"])\n",
    "    #print(fvalues.shape, pvalues.shape)\n",
    "    # df_features[\"q\"] = (df_features[\"q\"] - df_features[\"q\"].mean()) / df_features[\"q\"].std()\n",
    "    m = OLS(df_features[\"q\"], X)\n",
    "    r = m.fit()\n",
    "    #print(r.params)\n",
    "    plt.xticks(ha='right', rotation=55, fontsize=6)\n",
    "    sns.barplot(x=X.columns, y=r.params)\n",
    "    plt.title((problem, n, k))\n",
    "    #plt.savefig(\"experiments/figures/NORA/features/\"+filename([\"features\", file, problem])+\".jpg\", dpi=400, bbox_inches=\"tight\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "#file = \"5mill_JE20\"\n",
    "#problems = [\"AT\", \"BW\", \"DP\", \"TA\"]\n",
    "file = \"5mill_JE_NORA\"\n",
    "for problem, n, k in [(x, 2, 2) for x in problems]:\n",
    "    plot_features(problem, n, k, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem, n, k = \"CM\", 2, 2\n",
    "last = False\n",
    "ra_feature = True\n",
    "dir = \"ra_feature_2h\"\n",
    "\n",
    "problem2, n2, k2 = (problem, 3, 3) if problem != \"CM\" else (problem, 2, 2)\n",
    "df = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+dir+\"/\"+filename([problem2, n2, k2])+\".csv\")\n",
    "idx = best_agent_idx(df) if not last else last_agent_idx(df)\n",
    "t = \"last\" if last else \"best\"\n",
    "df_features = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+dir+\"/\"+t+\"_\"+str(idx)+\".csv\")\n",
    "\n",
    "m = LinearRegression()\n",
    "m.fit(df_features[feature_names(ra_feature)], df_features[\"q\"])\n",
    "features = feature_names(ra_feature)\n",
    "print(problem, m.rank_, m.intercept_)\n",
    "print(m.coef_)\n",
    "print(m.score(df_features[feature_names(ra_feature)], df_features[\"q\"]))\n",
    "df_features[\"pred\"] = m.predict(df_features[feature_names(ra_feature)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "[]\n",
    "print(np.dot(m.coef_, [ for i in range(14)])+m.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-notice",
   "metadata": {},
   "source": [
    "# Q Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def plot_features(problem, n, k, dir, last=False, ra_feature=True):\n",
    "    problem2, n2, k2 = (problem, 3, 3) if problem != \"CM\" else (problem, 2, 2)\n",
    "    df = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+dir+\"/\"+filename([problem2, n2, k2])+\".csv\")\n",
    "    idx = best_agent_idx(df) if not last else last_agent_idx(df)\n",
    "    t = \"last\" if last else \"best\"\n",
    "    df_features = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+dir+\"/\"+t+\"_\"+str(idx)+\".csv\")\n",
    "    \n",
    "    df_features[\"q\"].plot(kind='hist');\n",
    "    plt.title((problem, n, k))\n",
    "    #plt.savefig(\"experiments/figures/2h/\"+t+\"_features/\"+filename([problem, n, k, t, ra_feature])+\".jpg\", dpi=200, bbox_inches=\"tight\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "problems = [\"AT\", \"TA\", \"TL\", \"DP\", \"BW\", \"CM\"]\n",
    "for problem, n, k in [(x, 2, 2) for x in problems]:\n",
    "    plot_features(problem, n, k, \"ra_feature_2h\", last=False, ra_feature=True)\n",
    "    #plot_features(problem, n, k, \"ra_feature_2h\", last=False, ra_feature=False)\n",
    "    #plot_features(problem, n, k, \"ra_feature_2h\", last=True, ra_feature=True)\n",
    "    #plot_features(problem, n, k, \"ra_feature_2h\", last=True, ra_feature=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-incident",
   "metadata": {},
   "source": [
    "## Feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extra-humidity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "AT 15528.0 0.7056898745682603\n",
      "True\n",
      "BW 24642.0 0.7132272069464544\n",
      "True\n",
      "DP 32687.0 0.7516672032378237\n",
      "True\n",
      "TA 58071.0 0.7796334832516614\n",
      "True\n",
      "TL 141870.0 0.7866022022865634\n",
      "True\n",
      "CM 223851.0 0.914345583099489\n"
     ]
    }
   ],
   "source": [
    "enabled_features = [\"ra feature\", \"labels\", \"state labels\", \"context features\", \"prop feature\", \"nk feature\", \"je feature\"]\n",
    "n = 2\n",
    "states_file = \"states_prop.pkl\"\n",
    "dfs = []\n",
    "problems = [\"AT\", \"BW\", \"DP\", \"TA\", \"TL\", \"CM\"]\n",
    "for problem in problems:\n",
    "    features = feature_names({f: True for f in enabled_features}, problem)\n",
    "    df = {name: [] for name in features}\n",
    "    with open(\"experiments/results/\"+filename([problem, n, n])+\"/\"+states_file, \"rb\") as f:\n",
    "        states = pickle.load(f)\n",
    "    for s in states:\n",
    "        for a in s:\n",
    "            for i in range(len(features)):\n",
    "                df[features[i]].append(a[i])\n",
    "    df = pd.DataFrame(df)\n",
    "    df[\"problem\"] = problem\n",
    "    dfs.append(df)\n",
    "    print(problem, df[\"in open\"].sum(), df[\"in open\"].sum() / df.shape[0])\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pressing-business",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ra type', '1 / ra distance', 'in open', 'goals found',\n",
      "       'marked states found', 'pot winning loops found', 'frontier / explored',\n",
      "       'state extendFlight', 'state aircrash', 'state approach',\n",
      "       ...\n",
      "       'state mouseturn', 'state catturn', 'state mousemove', 'state catmove',\n",
      "       'state safe', 'mouseturn', 'catturn', 'mousemove', 'catmove', 'safe'],\n",
      "      dtype='object', length=114)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "packed-activation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT\n",
      "0.00    22001\n",
      "0.50        2\n",
      "0.25        1\n",
      "Name: in PG ancestors, dtype: int64\n",
      "BW\n",
      "0.0    34550\n",
      "Name: in PG ancestors, dtype: int64\n",
      "DP\n",
      "0.0    43486\n",
      "Name: in PG ancestors, dtype: int64\n",
      "TA\n",
      "0.0    74485\n",
      "Name: in PG ancestors, dtype: int64\n",
      "TL\n",
      "0.000000    180052\n",
      "0.111111        59\n",
      "0.500000        54\n",
      "0.037037        28\n",
      "0.200000        25\n",
      "0.052632        20\n",
      "0.045455        17\n",
      "0.055556        15\n",
      "0.166667        12\n",
      "0.071429        10\n",
      "0.034483        10\n",
      "0.020408         8\n",
      "0.024390         6\n",
      "0.047619         6\n",
      "0.090909         6\n",
      "0.100000         6\n",
      "0.019608         5\n",
      "0.016949         4\n",
      "0.018182         4\n",
      "0.015873         4\n",
      "0.142857         3\n",
      "0.076923         1\n",
      "0.043478         1\n",
      "0.083333         1\n",
      "0.062500         1\n",
      "Name: in PG ancestors, dtype: int64\n",
      "CM\n",
      "0.0    244821\n",
      "Name: in PG ancestors, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for problem in problems:\n",
    "    print(problem)\n",
    "    dfp = df.loc[df[\"problem\"] == problem]\n",
    "    print(dfp[\"in PG ancestors\"].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "determined-dating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ra type', '1 / ra distance', 'in open', 'goals found',\n",
      "       'marked states found', 'pot winning loops found', 'frontier / explored',\n",
      "       'state extendFlight', 'state aircrash', 'state approach',\n",
      "       ...\n",
      "       'state mouseturn', 'state catturn', 'state mousemove', 'state catmove',\n",
      "       'state safe', 'mouseturn', 'catturn', 'mousemove', 'catmove', 'safe'],\n",
      "      dtype='object', length=114)\n",
      "True\n",
      "['ra type', '1 / ra distance', 'in open', 'goals found', 'marked states found', 'pot winning loops found', 'frontier / explored', 'state extendFlight', 'state aircrash', 'state approach', 'state requestLand', 'state landcrash', 'state controlall', 'state descend', 'state land', 'extendFlight', 'aircrash', 'approach', 'requestLand', 'landcrash', 'controlall', 'descend', 'land', 'action controllable', '1 / depth', 'state portion explored', 'state portion controllable', 'state marked', 'child marked', 'child goal', 'child error', 'child none', 'child deadlock', 'child portion controllable', 'child portion explored', 'last state expanded from', 'last state expanded to', 'n', 'k', 'in loop', 'forced in FNG', 'in PG ancestors', 'forced in PG']\n",
      "0.00    22001\n",
      "0.50        2\n",
      "0.25        1\n",
      "Name: in PG ancestors, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "problem = \"AT\"\n",
    "dfp = df.loc[df[\"problem\"] == problem]\n",
    "print(dfp.columns)\n",
    "features = feature_names({f: True for f in enabled_features}, problem)\n",
    "print(features)\n",
    "print(dfp[\"in PG ancestors\"].value_counts())\n",
    "for name in features[-4:]:\n",
    "    dfp[name].plot(kind='hist')\n",
    "    plt.title((name, problem))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-chosen",
   "metadata": {},
   "source": [
    "## Analyzing nn weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-words",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import numpy_helper\n",
    "\n",
    "weights = []\n",
    "for idx in range(100):\n",
    "    onnx_model = onnx.load(\"experiments/results/AT_3_3/5mill/\" + str(idx)+\".onnx\")\n",
    "    INTIALIZERS  = onnx_model.graph.initializer\n",
    "    onnx_weights = {}\n",
    "    for initializer in INTIALIZERS:\n",
    "        W = numpy_helper.to_array(initializer)\n",
    "        onnx_weights[initializer.name] = W\n",
    "    w = onnx_weights[\"coefficient\"]\n",
    "    if True:\n",
    "        for key, value in onnx_weights.items():\n",
    "            if key == \"coefficient1\":\n",
    "                print(key, value.min(), value.max())\n",
    "    for feature in range(w.shape[0]):\n",
    "        for node in range(w.shape[1]):\n",
    "            weights.append({\"t\": idx, \"val\": w[feature, node], \"feature\": feature, \"node\": node})\n",
    "    \n",
    "weights = pd.DataFrame(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in range(23):\n",
    "    print(feature_names({\"ra feature\": True}, \"AT\")[feature])\n",
    "    df = weights.loc[weights[\"feature\"] == feature]\n",
    "    sns.lineplot(data=df, x=\"t\", y=\"val\", hue=\"node\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
