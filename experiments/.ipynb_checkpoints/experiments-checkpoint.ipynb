{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "postal-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from prettytable import PrettyTable\n",
    "import pprint\n",
    "import pickle\n",
    "import json\n",
    "import os, sys\n",
    "os.chdir(\"../\")\n",
    "sys.path.append('src/')\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-mandate",
   "metadata": {},
   "source": [
    "# Monolithic and RA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pleasant-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_df(df, m):\n",
    "    added = []\n",
    "    for n in range(1, m+1):\n",
    "        for k in range(1, m+1):\n",
    "            if len(df.loc[(df[\"n\"] == n) & (df[\"k\"] == k)]) == 0:\n",
    "                added.append({\"n\": n, \"k\": k, \"expanded transitions\": float(\"inf\"), \"synthesis time(ms)\": float(\"inf\")})\n",
    "    df = pd.concat([df, pd.DataFrame(added)], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "monolithic_results = {}\n",
    "for problem in [\"AT\", \"TA\", \"TL\", \"DP\", \"BW\", \"CM\"]:\n",
    "    df = pd.read_csv(\"experiments/results/ResultsPaper/\"+problem+\".csv\")\n",
    "    df = df.loc[df[\"controllerType\"] == \"mono\"]\n",
    "    df[\"n\"] = df[\"testcase\"].apply(lambda t: int(t.split(\"-\")[1]))\n",
    "    df[\"k\"] = df[\"testcase\"].apply(lambda t: int(t.split(\"-\")[2]))\n",
    "    df = fill_df(df, 15)\n",
    "    monolithic_results[\"expanded transitions\", problem] = df.pivot(\"n\", \"k\", \"expandedTransitions\")\n",
    "    monolithic_results[\"synthesis time(ms)\", problem] = df.pivot(\"n\", \"k\", \"synthesisTimeMs\")\n",
    "\n",
    "\n",
    "ra_results = {}\n",
    "for problem in [\"AT\", \"TA\", \"TL\", \"DP\", \"BW\", \"CM\"]:\n",
    "    df = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/all_ra_afterfix_15.csv\")\n",
    "    df = fill_df(df, 15)\n",
    "    ra_results[\"expanded transitions\", problem] = df.pivot(\"n\", \"k\", \"expanded transitions\")\n",
    "    ra_results[\"synthesis time(ms)\", problem] = df.pivot(\"n\", \"k\", \"synthesis time(ms)\")\n",
    "    \n",
    "random_results_small = {}\n",
    "for problem in [\"AT\", \"TA\", \"TL\", \"DP\", \"BW\", \"CM\"]:\n",
    "    for n, k in [(2, 2), (3, 3)]:\n",
    "        df = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/random.csv\")\n",
    "        random_results_small[(problem, n, k)] = list(df[\"expanded transitions\"])\n",
    "        \n",
    "random_results = {}\n",
    "for problem in [\"AT\", \"TA\", \"TL\", \"DP\", \"BW\", \"CM\"]:\n",
    "    df = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/all_random.csv\")\n",
    "    df = fill_df(df, 15)\n",
    "    random_results[\"expanded transitions\", problem] = df.pivot(\"n\", \"k\", \"expanded transitions\")\n",
    "    random_results[\"synthesis time(ms)\", problem] = df.pivot(\"n\", \"k\", \"synthesis time(ms)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "given-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ra_expanded_transitions(problem, n, k, norm=False, label=\"RA\", color=\"r\"):\n",
    "    ra = ra_results[\"expanded transitions\", problem][n][k]\n",
    "    mono = monolithic_results[\"expanded transitions\", problem][n][k]\n",
    "    if norm:\n",
    "        print(\"RA\", ra/mono)\n",
    "        plt.text(5, ra/mono, \"RA\")\n",
    "        plt.axhline(y=ra/mono, color=color, linestyle='-', label=label)\n",
    "    else:\n",
    "        print(\"RA\", ra)\n",
    "        plt.text(5, ra, \"RA\")\n",
    "        plt.axhline(y=ra, color=color, linestyle='-', label=label)\n",
    "\n",
    "def plot_random_expanded_transitions(problem, n, k, norm=False, label=\"Random\", color=\"g\", use_min=False):\n",
    "    if use_min:\n",
    "        random = min(random_results_small[(problem, n, k)])\n",
    "    else:\n",
    "        random = np.mean(random_results_small[(problem, n, k)])\n",
    "    mono = monolithic_results[\"expanded transitions\", problem][n][k]\n",
    "    # print(ra, mono, ra/mono)\n",
    "    if norm:\n",
    "        plt.text(5, random/mono, label)\n",
    "        plt.axhline(y=random/mono, color=color, linestyle='-', label=label)\n",
    "    else:\n",
    "        plt.text(5, random, label)\n",
    "        plt.axhline(y=random, color=color, linestyle='-', label=label)\n",
    "    \n",
    "    \n",
    "def df_preprocess(df, base, window_size=4):\n",
    "    df[\"rounded training time\"] = df[\"training time\"] // base * base\n",
    "    df[\"rounded training steps\"] = df[\"training steps\"] // base * base\n",
    "\n",
    "    df[\"best transitions\"] = df[\"expanded transitions\"].cummin()\n",
    "    \n",
    "    df[\"mean transitions\"] = list(np.convolve(list(df[\"expanded transitions\"]), np.ones(window_size), mode='valid')/window_size)+[np.nan for _ in range(window_size-1)]\n",
    "    df[\"total transitions\"] = df.apply(lambda r: monolithic_results[\"expanded transitions\", r[\"problem\"]][r[\"n\"]][r[\"k\"]], axis=1)\n",
    "    df[\"expanded transitions / total\"] = df[\"expanded transitions\"] / df[\"total transitions\"]\n",
    "    df[\"mean transitions / total\"] = df[\"mean transitions\"] / df[\"total transitions\"]\n",
    "    \n",
    "    df[\"instance\"] = df.apply((lambda r: (r[\"problem\"], r[\"n\"], r[\"k\"])), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-satellite",
   "metadata": {},
   "source": [
    "# Comparing transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "problems = [\"AT\", \"DP\"]\n",
    "#files = [\"1mill\", \"T_1mill\", \"B_1mill\", \"TB_1mill\"]\n",
    "#files = [\"TB_5mill\", \"ra_feature2opt_2h\", \"base_features_2h\"]\n",
    "#files = [\"ra_feature2opt_2h\"]\n",
    "#files = [\"base_features_2h\", \"ra_feature2opt_2h\", \"TB_5mill\", \"labels_2h\"]\n",
    "#files = [\"TB_5mill_2000\", \"TB_5mill_5000\", \"TB_5mill\", \"ra_feature2opt_2h\"]\n",
    "files = [\"base_features_2h\", \"ra_feature2opt_2h\", \"5mill_RA\", \"5mill_L\", \"TB_5mill\", \"labels_2h\"]\n",
    "files = [\"5mill_C\", \"5mill_L\", \"5mill_RA\", \"ra_feature2opt_2h\"]\n",
    "#files = [\"5mill_C\"]\n",
    "for problem in problems:\n",
    "    dfs = []\n",
    "    n2, k2 = 3, 3\n",
    "    for n, k, file  in [(2, 2, f) for f in files]:\n",
    "        dfs.append(pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+file+\"/\"+filename([problem, n2, k2])+\".csv\"))\n",
    "        df_preprocess(dfs[-1], 200000, 8)\n",
    "        #if file == \"5mill_C\":\n",
    "        #    dfs[-1] = dfs[-1].loc[dfs[-1][\"idx\"] % 5 == 0]\n",
    "        dfs[-1][\"case\"] = filename([n, k, file])\n",
    "        \n",
    "        print(problem, file, dfs[-1][\"expanded transitions\"].dropna().min())\n",
    "        print(list(dfs[-1].loc[dfs[-1][\"expanded transitions\"] == dfs[-1][\"expanded transitions\"].min()][\"idx\"]))\n",
    "    \n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    sns.lineplot(data = df, x=\"training steps\", y=\"expanded transitions\", hue=\"case\")\n",
    "\n",
    "    plot_ra_expanded_transitions(problem, n2, k2, norm=False)\n",
    "    #plot_random_expanded_transitions(problem, n2, k2, norm=False, label=\"Random mean\")\n",
    "    #plot_random_expanded_transitions(problem, n2, k2, norm=False, use_min=True, label=\"Random min\")\n",
    "    plt.title(\" \".join([problem, str(n2), str(k2)]))\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"experiments/figures/TB/batch size/\"+filename([problem2, n2, k2])+\"_bs_3_3.jpg\", dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-extraction",
   "metadata": {},
   "source": [
    "## Comparing transitions from different n and k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\"AT\"]\n",
    "\n",
    "#files = [\"1mill\", \"T_1mill\", \"B_1mill\", \"TB_1mill\"]\n",
    "#files = [\"TB_5mill\", \"ra_feature2opt_2h\", \"base_features_2h\"]\n",
    "#files = [\"ra_feature2opt_2h\"]\n",
    "#files = [\"base_features_2h\", \"ra_feature2opt_2h\", \"TB_5mill\", \"labels_2h\"]\n",
    "#files = [\"TB_5mill_2000\", \"TB_5mill_5000\", \"TB_5mill\", \"ra_feature2opt_2h\"]\n",
    "files = [\"labels_2h\", \"TB_5mill\", \"ra_feature2opt_2h\"]\n",
    "#files = [\"TB_5mill\", \"labels_2h\"]\n",
    "files = [\"5mill\", \"1mill_eta1e-4\"]\n",
    "\n",
    "for problem in problems:\n",
    "    dfs = []\n",
    "    n, k, file = (3, 3, \"5mill\")\n",
    "    for n2 in range(1, 5):\n",
    "        for k2 in range(1, 5):\n",
    "            dfs.append(pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+file+\"/\"+filename([problem, n2, k2])+\".csv\"))\n",
    "            df_preprocess(dfs[-1], 200000, 20)\n",
    "            dfs[-1][\"case\"] = filename([n, k, file, n2, k2])\n",
    "\n",
    "            print(problem, file, n2, k2, dfs[-1][\"expanded transitions\"].dropna().min())\n",
    "            #print(list(dfs[-1].loc[dfs[-1][\"expanded transitions\"] == dfs[-1][\"expanded transitions\"].min()][\"idx\"]))\n",
    "    \n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    sns.lineplot(data = df, x=\"training steps\", y=\"mean transitions / total\", hue=\"case\")\n",
    "\n",
    "    #plot_ra_expanded_transitions(problem, n2, k2, norm=False)\n",
    "    #plot_random_expanded_transitions(problem, n2, k2, norm=False, label=\"Random mean\")\n",
    "    #plot_random_expanded_transitions(problem, n2, k2, norm=False, use_min=True, label=\"Random min\")\n",
    "    plt.title(\" \".join([problem, str(n), str(k)]))\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"experiments/figures/TB/batch size/\"+filename([problem2, n2, k2])+\"_bs_3_3.jpg\", dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-convention",
   "metadata": {},
   "source": [
    "## Transitions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"base_features_2h\", \"ra_feature2opt_2h\", \"TB_5mill\", \"labels_2h\"]\n",
    "#files = [\"base_features_2h\", \"ra_feature2opt_2h\"]\n",
    "#files = [\"ra_feature2opt_2h\", \"TB_5mill\"]\n",
    "#files = [\"base_features_2h\", \"ra_feature2opt_2h\", \"5mill_RA\", \"5mill_L\"]\n",
    "files = [\"base_features_2h\", \"ra_feature2opt_2h\", \"5mill_RA\", \"5mill_L\", \"TB_5mill\", \"labels_2h\"]\n",
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "for problem in problems:\n",
    "    x = PrettyTable()\n",
    "    x.field_names = [problem, \"min 2\", \"min 3\", \"min mean 2\", \"idx mm2\", \"min mean 3\", \"idx mm3\", \"last q\", \"ra 2\", \"ra 3\"]\n",
    "    for file in files:\n",
    "        df_2_2 = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/\"+file+\"/\"+filename([problem, 2, 2])+\".csv\")\n",
    "        df_3_3 = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/\"+file+\"/\"+filename([problem, 3, 3])+\".csv\")\n",
    "        df_q = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/\"+file+\"/q.csv\")\n",
    "\n",
    "        min_2_2 = df_2_2[\"expanded transitions\"].min()\n",
    "        min_3_3 = df_3_3[\"expanded transitions\"].min()\n",
    "\n",
    "        window_size = 5\n",
    "        df_2_2[\"mean transitions\"] = list(np.convolve(list(df_2_2[\"expanded transitions\"]), np.ones(window_size), mode='valid')/window_size)+[np.nan for _ in range(window_size-1)]\n",
    "        df_3_3[\"mean transitions\"] = list(np.convolve(list(df_3_3[\"expanded transitions\"]), np.ones(window_size), mode='valid')/window_size)+[np.nan for _ in range(window_size-1)]\n",
    "        min_mean_2_2 = df_2_2[\"mean transitions\"].min()\n",
    "        min_mean_3_3 = df_3_3[\"mean transitions\"].min()\n",
    "        min_mean_idx_2_2 = df_2_2[\"mean transitions\"].argmin()\n",
    "        min_mean_idx_3_3 = df_3_3[\"mean transitions\"].argmin()\n",
    "        \n",
    "        ra_2_2 = ra_results[\"expanded transitions\", problem][2][2]\n",
    "        ra_3_3 = ra_results[\"expanded transitions\", problem][3][3]\n",
    "        last_q = -df_q.iloc[-1][\"avg q\"]\n",
    "        x.add_row([file, min_2_2, min_3_3, min_mean_2_2, min_mean_idx_2_2 / 100, min_mean_3_3, min_mean_idx_3_3 / 20, last_q, ra_2_2, ra_3_3])\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-diabetes",
   "metadata": {},
   "source": [
    "# Comparing avg Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "problems = [\"TA\"]\n",
    "\n",
    "files = [\"T_1mill\", \"TB_1mill\"]\n",
    "files = [\"1mill\", \"T_1mill\", \"B_1mill\", \"TB_1mill\"]\n",
    "files = [\"ra_feature2opt_2h\", \"ra_feature2_target\"]\n",
    "files = [\"TB_5mill\", \"ra_feature2opt_2h\"]\n",
    "files = [\"TB_5mill\", \"TB_5mill_2000\", \"TB_5mill_5000\"]\n",
    "files = [\"TB_5mill\", \"TB_5mill_b100000\"]\n",
    "files = [\"TB_5mill\", \"base_features_2h\"]\n",
    "files = [\"base_features_2h\", \"TB_5mill\", \"labels_2h\"]\n",
    "files = [\"base_features_2h\", \"ra_feature2opt_2h\", \"TB_5mill\", \"labels_2h\"]\n",
    "files = [\"TB_5mill_2000\", \"TB_5mill_5000\", \"TB_5mill\", \"ra_feature2opt_2h\"]\n",
    "files = [\"TB_5mill\", \"TB_5mill_bs100\", \"ra_feature2opt_2h\", \"base_features_2h\"]\n",
    "files = [\"labels_2h\", \"ra_feature2opt_2h\"]\n",
    "files = [\"5mill\"]\n",
    "files = [\"normalized\", \"1mill_eta1e-4\"]\n",
    "files = [\"50mill\"]\n",
    "\n",
    "files = [\"base_features_2h\", \"ra_feature2opt_2h\", \"5mill_RA\", \"5mill_L\"]\n",
    "files = [\"base_features_2h\", \"ra_feature2opt_2h\", \"5mill_RA\", \"5mill_L\", \"TB_5mill\", \"labels_2h\"]\n",
    "files = [\"5mill_RA\", \"ra_feature2opt_2h\"]\n",
    "\n",
    "for problem, n, k in [(x, 2, 2) for x in problems]:\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        if file != \"ra_feature2opt_2h\" or problem != \"CM\":\n",
    "            dfs.append(pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+file+\"/q.csv\"))\n",
    "            dfs[-1][\"file\"] = file\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df[\"avg q\"] = -df[\"avg q\"]\n",
    "    sns.lineplot(data = df, x=\"training steps\", y=\"avg q\", hue=\"file\")\n",
    "    \n",
    "    plt.title(\" \".join([problem, str(n), str(k), \"q\"]))\n",
    "    plt.savefig(\"experiments/figures/q.jpg\", dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "for problem in problems:\n",
    "    print(problem, monolithic_results[(problem, 2, 2)], monolithic_results[(problem, 3, 3)], end=\" \")\n",
    "    print(monolithic_results[(problem, 4, 4)] if problem != \"CM\" else \"nan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-particle",
   "metadata": {},
   "source": [
    "## Time of evaluating up to 4 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "for problem in [\"AT\", \"BW\", \"DP\", \"TA\", \"TL\"]:\n",
    "    df_agent = pd.read_csv(\"experiments/results/\"+filename([problem, 2, 2])+\"/5mill_RA/all.csv\")\n",
    "    df_agent = fill_df(df_agent, 15)\n",
    "    agent_t = df_agent.pivot(\"n\", \"k\", \"synthesis time(ms)\")\n",
    "    agent_t = agent_t.fillna(float(\"inf\"))\n",
    "    print(problem, np.sum([(agent_t[n][k] if n != 4 or k != k else 0) for n in range(1, 4) for k in range(1, 4)]) / (1000*60) * 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-willow",
   "metadata": {},
   "source": [
    "# Plotting Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\"AT\", \"TA\", \"TL\", \"DP\", \"BW\", \"CM\"]\n",
    "for problem, n, k in [(x, 2, 2) for x in problems]:\n",
    "    df = pd.read_csv(\"experiments/results 25 mar/\"+filename([problem, n, k])+\"/10m_0.csv\")\n",
    "    df[\"avg q\"] = -df[\"avg q\"]\n",
    "    sns.lineplot(data=df, x=\"training time\", y=\"avg q\")\n",
    "    \n",
    "    plt.title(\" \".join([problem, str(n), str(k), \"q\"]))\n",
    "    \n",
    "    plt.savefig(\"experiments/figures/10m_0/q/\"+filename([problem, n, k])+\".jpg\", dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-equality",
   "metadata": {},
   "source": [
    "# Generalization correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "\n",
    "#files = [\"1mill\", \"T_1mill\", \"B_1mill\", \"TB_1mill\"]\n",
    "#files = [\"TB_5mill\", \"ra_feature2opt_2h\", \"base_features_2h\"]\n",
    "#files = [\"ra_feature2opt_2h\"]\n",
    "file = \"TB_5mill\"\n",
    "\n",
    "for problem, n, k in [(x, 2, 2) for x in problems]:\n",
    "    \n",
    "    df1 = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+file+\"/\"+filename([problem, 2, 2])+\".csv\")\n",
    "    df2 = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+file+\"/\"+filename([problem, 3, 3])+\".csv\")\n",
    "    print(len(df1), len(df2))\n",
    "    df = pd.DataFrame({\"transitions 2 2\": df1[\"expanded transitions\"], \"transitions 3 3\": df2[\"expanded transitions\"]})\n",
    "    \n",
    "    sns.regplot(data = df, x=\"transitions 2 2\", y=\"transitions 3 3\")\n",
    "    plt.title(problem+\" generalization correlation\")\n",
    "    #plt.savefig(\"experiments/figures/2h/trans/\"+filename([problem2, n2, k2, \"no_round\"])+\".jpg\", dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-approach",
   "metadata": {},
   "source": [
    "# Analyzing models output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "a = 0\n",
    "def plot_q_and_pred(m, df_features, features, problem):\n",
    "    print(problem, m.rank_, m.intercept_)\n",
    "    print(m.coef_)\n",
    "    print(m.score(df_features[features], df_features[\"q\"]))\n",
    "    print(df_features[\"q\"].min(), df_features[\"q\"].max())\n",
    "    df_features[\"pred\"] = m.predict(df_features[features])\n",
    "    df_features[\"pred\"].plot(kind=\"hist\")\n",
    "    plt.title((\"pred\", problem))\n",
    "    plt.show()\n",
    "    plt.title(\"q\")\n",
    "    df_features[\"q\"].plot(kind=\"hist\")\n",
    "    plt.title((\"q\", problem))\n",
    "    plt.show()\n",
    "\n",
    "def plot_features(problem, n, k, dir, last=False, ra_feature=True):\n",
    "    problem2, n2, k2 = problem, 3, 3\n",
    "    df = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+dir+\"/\"+filename([problem2, n2, k2])+\".csv\")\n",
    "    idx = best_agent_idx(df) if not last else last_agent_idx(df)\n",
    "    t = \"last\" if last else \"best\"\n",
    "    df_features = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+dir+\"/\"+t+\"_\"+str(idx)+\".csv\")\n",
    "    \n",
    "    features = feature_names({\"ra feature\": True}, problem)\n",
    "    \n",
    "    print(problem)\n",
    "    \n",
    "    #m = LinearRegression()\n",
    "    #m.fit(df_features[features], df_features[\"q\"])\n",
    "    #plot_q_and_pred(m, df_features, features, problem)\n",
    "    \n",
    "    constant_filter = VarianceThreshold(threshold=0)\n",
    "    constant_filter.fit(df_features[features])\n",
    "    constant_columns = [column for column in df_features[features].columns if column not in df_features[features].columns[constant_filter.get_support()]]\n",
    "    print(\"Constant columns: \", constant_columns)\n",
    "    X = df_features[features].loc[:, constant_filter.get_support()]\n",
    "    #fvalues, pvalues = f_regression(X, df_features[\"q\"])\n",
    "    #print(fvalues.shape, pvalues.shape)\n",
    "    df_features[\"q\"] = (df_features[\"q\"] - df_features[\"q\"].mean()) / df_features[\"q\"].std()\n",
    "    m = OLS(df_features[\"q\"], X)\n",
    "    r = m.fit()\n",
    "    print(r.params)\n",
    "    plt.xticks(ha='right', rotation=55, fontsize=8)\n",
    "    sns.barplot(x=X.columns, y=r.params)\n",
    "    plt.title((problem, n, k))\n",
    "    plt.savefig(\"experiments/figures/labels_2h/\"+t+\"_features/\"+filename([problem, n, k, t, ra_feature])+\".jpg\", dpi=200, bbox_inches=\"tight\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "for problem, n, k in [(x, 2, 2) for x in problems]:\n",
    "    plot_features(problem, n, k, \"labels_2h\", last=False, ra_feature=True)\n",
    "    #plot_features(problem, n, k, \"TB_5mill\", last=True, ra_feature=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem, n, k = \"CM\", 2, 2\n",
    "last = False\n",
    "ra_feature = True\n",
    "dir = \"ra_feature_2h\"\n",
    "\n",
    "problem2, n2, k2 = (problem, 3, 3) if problem != \"CM\" else (problem, 2, 2)\n",
    "df = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+dir+\"/\"+filename([problem2, n2, k2])+\".csv\")\n",
    "idx = best_agent_idx(df) if not last else last_agent_idx(df)\n",
    "t = \"last\" if last else \"best\"\n",
    "df_features = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+dir+\"/\"+t+\"_\"+str(idx)+\".csv\")\n",
    "\n",
    "m = LinearRegression()\n",
    "m.fit(df_features[feature_names(ra_feature)], df_features[\"q\"])\n",
    "features = feature_names(ra_feature)\n",
    "print(problem, m.rank_, m.intercept_)\n",
    "print(m.coef_)\n",
    "print(m.score(df_features[feature_names(ra_feature)], df_features[\"q\"]))\n",
    "df_features[\"pred\"] = m.predict(df_features[feature_names(ra_feature)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "[]\n",
    "print(np.dot(m.coef_, [ for i in range(14)])+m.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-notice",
   "metadata": {},
   "source": [
    "# Q Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def plot_features(problem, n, k, dir, last=False, ra_feature=True):\n",
    "    problem2, n2, k2 = (problem, 3, 3) if problem != \"CM\" else (problem, 2, 2)\n",
    "    df = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+dir+\"/\"+filename([problem2, n2, k2])+\".csv\")\n",
    "    idx = best_agent_idx(df) if not last else last_agent_idx(df)\n",
    "    t = \"last\" if last else \"best\"\n",
    "    df_features = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+dir+\"/\"+t+\"_\"+str(idx)+\".csv\")\n",
    "    \n",
    "    df_features[\"q\"].plot(kind='hist');\n",
    "    plt.title((problem, n, k))\n",
    "    #plt.savefig(\"experiments/figures/2h/\"+t+\"_features/\"+filename([problem, n, k, t, ra_feature])+\".jpg\", dpi=200, bbox_inches=\"tight\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "problems = [\"AT\", \"TA\", \"TL\", \"DP\", \"BW\", \"CM\"]\n",
    "for problem, n, k in [(x, 2, 2) for x in problems]:\n",
    "    plot_features(problem, n, k, \"ra_feature_2h\", last=False, ra_feature=True)\n",
    "    #plot_features(problem, n, k, \"ra_feature_2h\", last=False, ra_feature=False)\n",
    "    #plot_features(problem, n, k, \"ra_feature_2h\", last=True, ra_feature=True)\n",
    "    #plot_features(problem, n, k, \"ra_feature_2h\", last=True, ra_feature=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-story",
   "metadata": {},
   "source": [
    "## Training time proportional to size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "\n",
    "#files = [\"1mill\", \"T_1mill\", \"B_1mill\", \"TB_1mill\"]\n",
    "#files = [\"TB_5mill\", \"ra_feature2opt_2h\", \"base_features_2h\"]\n",
    "#files = [\"ra_feature2opt_2h\"]\n",
    "files = [\"base_features_2h\", \"ra_feature2opt_2h\", \"TB_5mill\", \"labels_2h\"]\n",
    "#files = [\"TB_5mill\", \"labels_2h\"]\n",
    "\n",
    "for problem, n, k in [(x, 2, 2) for x in problems]:\n",
    "    problem2, n2, k2 = problem, 2, 2\n",
    "    \n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        dfs.append(pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+file+\"/\"+filename([problem2, n2, k2])+\".csv\"))\n",
    "        if problem == \"TA\" and n2 == 3:\n",
    "            dfs[-1] = dfs[-1].loc[dfs[-1][\"idx\"] % 5 == 0]\n",
    "        df_preprocess(dfs[-1], 1, 8)\n",
    "        size = monolithic_results[(problem2, n2, k2)]\n",
    "        dfs[-1] = dfs[-1].loc[dfs[-1][\"training steps\"] < size * 10000]\n",
    "        dfs[-1][\"file\"] = file\n",
    "        # print(problem, file, dfs[-1][\"synthesis time(ms)\"].dropna().min(), \"(ms)\")\n",
    "        print(problem, file, dfs[-1][\"expanded transitions\"].dropna().min(), \"(trans)\")\n",
    "        print(list(dfs[-1].loc[dfs[-1][\"expanded transitions\"] == dfs[-1][\"expanded transitions\"].min()][\"idx\"]))\n",
    "        if problem == \"CM\" and n2 == 3:\n",
    "            print(dfs[-1].dropna(subset=[\"expanded transitions\"])[[\"idx\", \"expanded transitions\"]])\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    sns.lineplot(data = df, x=\"rounded training steps\", y=\"mean transitions\", hue=\"file\")\n",
    "    \n",
    "    plot_ra_expanded_transitions(problem2, n2, k2, norm=False)\n",
    "    plot_random_expanded_transitions(problem2, n2, k2, norm=False, label=\"Random mean\")\n",
    "    plot_random_expanded_transitions(problem2, n2, k2, norm=False, use_min=True, label=\"Random min\")\n",
    "    plt.title(\" \".join([problem, str(n), str(k), \"->\", problem2, str(n2), str(k2)]))\n",
    "    plt.savefig(\"experiments/figures/TB/\"+filename([problem2, n2, k2])+\"_best_trans.jpg\", dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-steal",
   "metadata": {},
   "source": [
    "## Training complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = [\"ra_feature2_target\", \"ra_feature2_2h\"]\n",
    "\n",
    "problems = [\"AT\", \"TA\", \"TL\", \"DP\", \"BW\"]\n",
    "for problem, n, k in [(x, 2, 2) for x in problems]:\n",
    "    problem2, n2, k2 = problem, 2, 2\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        dfs.append(pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/\"+file+\"/\"+filename([problem2, n2, k2])+\".csv\"))\n",
    "        dfs[-1][\"file\"] = file\n",
    "        print(dfs[-1][\"training steps\"].max())\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    sns.scatterplot(data=df, x=\"training time\", y=\"training steps\", hue = \"file\")\n",
    "    plt.title(\" \".join([problem, str(n), str(k)]))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-whale",
   "metadata": {},
   "source": [
    "# Exploration complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\"AT\", \"TA\", \"BW\", \"TL\", \"DP\"]\n",
    "f, axs = plt.subplots(1, len(problems), figsize=(5*len(problems), 6))\n",
    "\n",
    "for i in range(len(problems)):\n",
    "    df_agent = pd.read_csv(\"experiments/results 25 mar/\"+filename([problems[i], 2, 2])+\"/Agent15.csv\")\n",
    "    df_ra = pd.read_csv(\"experiments/results 25 mar/\"+filename([problems[i], 2, 2])+\"/RA15.csv\")\n",
    "    df_agent[\"approach\"] = \"Agent\"\n",
    "    df_ra[\"approach\"] = \"RA\"\n",
    "    \n",
    "    sns.lineplot(data=pd.concat([df_agent, df_ra], ignore_index=True), x=\"expanded transitions\", y=\"synthesis time(ms)\", ax=axs[i], hue=\"approach\")\n",
    "    axs[i].set_title(problems[i], fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"experiments/figures/overhead.jpg\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-constraint",
   "metadata": {},
   "source": [
    "## Frontier sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\"AT\", \"BW\", \"CM\", \"DP\", \"TA\", \"TL\"]\n",
    "n, k = 2, 2\n",
    "ra_feature = True\n",
    "dfs = []\n",
    "for problem in problems:\n",
    "    mono = monolithic_results[\"expanded transitions\", problem][n][k]\n",
    "    print(mono)\n",
    "    df = pd.read_csv(\"experiments/results/\"+filename([problem, n, k])+\"/frontiers\"+(\"RA\" if ra_feature else \"\")+\".csv\")\n",
    "    df[\"problem\"] = problem\n",
    "    print(df[\"frontier size\"].max())\n",
    "    df[\"rel frontier size\"] = df[\"frontier size\"] / mono\n",
    "    df[\"frontier size / expanded\"] = df[\"frontier size\"] / df[\"step\"].max()\n",
    "    df[\"rel step\"] = df[\"step\"] / df[\"step\"].max()\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "sns.lineplot(data=df.loc[df[\"problem\"] == \"DP\"], x=\"rel step\", y=\"frontier size\", hue=\"ep\", ci=None)\n",
    "#plt.savefig(\"experiments/figures/frontiers_\"+str(n)+\"_\"+str(k)+\".jpg\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-office",
   "metadata": {},
   "source": [
    "# RA refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap_time(df, ax, file):\n",
    "    dfp = df.pivot(\"n\", \"k\", \"synthesis time(ms)\")\n",
    "    if file == \"all_r_15.csv\":\n",
    "        for n in range(2, 16):\n",
    "            for k in range(2, 16):\n",
    "                if np.isnan(dfp[n-1][k]) or np.isnan(dfp[n][k-1]):\n",
    "                    dfp[n][k] = np.NaN\n",
    "    sns.heatmap(data=dfp, cmap=sns.cm.rocket_r, ax=ax, xticklabels=range(1, 16), yticklabels=range(1, 16), vmin=0, vmax=500000)\n",
    "    ax.set_ylim(0, 15)\n",
    "    ax.set_xlim(0, 15)\n",
    "        \n",
    "\n",
    "problems = [\"AT\", \"TA\", \"BW\", \"TL\", \"DP\", \"CM\"]\n",
    "files = [(\"all_ra_old_15_old.csv\", \"Pre-Refactor\"), (\"all_ra_afterfix_15.csv\", \"Afterfix\")]\n",
    "f, axs = plt.subplots(len(files), len(problems), figsize = (5*len(problems), 5*len(files)))\n",
    "\n",
    "\n",
    "for i in range(len(files)):\n",
    "    file, name = files[i]\n",
    "    for j in range(len(problems)):\n",
    "        df = pd.read_csv(\"experiments/results/\"+filename([problems[j], 2, 2])+\"/\"+file)\n",
    "        plot_heatmap_time(df, axs[i][j], file)\n",
    "    axs[i][0].set_ylabel(files[i][1], fontsize=30)\n",
    "for i in range(len(problems)):\n",
    "    axs[0][i].set_title(problems[i], fontsize=24)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"experiments/figures/refactor_and_fix.jpg\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-digit",
   "metadata": {},
   "source": [
    "# Heuristic time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comp_solved_df(df_agent_p, df_ra_p):\n",
    "    df1 = df_agent_p.fillna(float(\"inf\"))\n",
    "    df2 = df_ra_p.fillna(float(\"inf\"))\n",
    "    df1 = df1 != float(\"inf\")\n",
    "    df2 = df2 != float(\"inf\")\n",
    "    return 1*((df1 == df2) & df1) + 2*(df2 > df1) + 3*(df1 > df2)\n",
    "\n",
    "problems = [\"AT\", \"TA\", \"BW\", \"TL\", \"DP\"]\n",
    "f, axs = plt.subplots(1, len(problems), figsize=(10*len(problems), 12))\n",
    "\n",
    "\n",
    "for i in range(len(problems)):\n",
    "    df_agent = pd.read_csv(\"experiments/results/\"+filename([problems[i], 2, 2])+\"/labels_2h/all.csv\")\n",
    "    df_agent = fill_df(df_agent, 15)\n",
    "    df_agent[\"heuristic time rel\"] = df_agent[\"heuristic time(ms)\"] / df_agent[\"synthesis time(ms)\"]\n",
    "    df_agent_p = df_agent.pivot(\"n\", \"k\", \"heuristic time rel\")\n",
    "    sns.heatmap(data=df_agent_p, ax=axs[i], cmap=sns.cm.rocket_r, annot=True)\n",
    "    axs[i].invert_yaxis()\n",
    "    axs[i].set_title(problems[i], fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"experiments/figures/agent_heuristic_time.jpg\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-verification",
   "metadata": {},
   "source": [
    "# 15 15 Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "juvenile-trustee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_comp_solved_df(agent, ra):\n",
    "    only_ra = ((agent == float(\"inf\")) & (ra != float(\"inf\")))\n",
    "    only_agent = ((agent != float(\"inf\")) & (ra == float(\"inf\")))\n",
    "    both = ((agent != float(\"inf\")) & (ra != float(\"inf\")))\n",
    "    \n",
    "    return only_ra*1 + only_agent*2 + both*(3*(agent > ra) + 4*(agent == ra) + 5*(agent < ra))\n",
    "\n",
    "def onlyifsolvedlast(res):\n",
    "    for n in range(1, 16):\n",
    "        for k in range(1, 16):\n",
    "            if (n > 1 and res[n-1][k] == float(\"inf\")) or (k > 1 and res[n][k-1] == float(\"inf\")):\n",
    "                res[n][k] = float(\"inf\")\n",
    "    return res\n",
    "\n",
    "problems = [\"AT\", \"TA\", \"BW\", \"TL\", \"DP\"]\n",
    "problems = [\"AT\", \"DP\"]\n",
    "f, axs = plt.subplots(1, len(problems), figsize=(5*len(problems), 6))\n",
    "\n",
    "def df_agent(problem, agent_file):\n",
    "    df_agent = pd.read_csv(\"experiments/results/\"+filename([problems[i], 2, 2])+\"/\"+agent_file)\n",
    "    #df_agent = pd.read_csv(\"experiments/results 25 mar/\"+filename([problems[i], 2, 2])+\"/all_e_15.csv\")\n",
    "    df_agent = fill_df(df_agent, 15)\n",
    "    agent_t = df_agent.pivot(\"n\", \"k\", \"expanded transitions\")\n",
    "    agent_t = agent_t.fillna(float(\"inf\"))\n",
    "    return onlyifsolvedlast(agent_t)\n",
    "    \n",
    "def df_comp(problem, comp_df):\n",
    "    comp_t = comp_df[\"expanded transitions\", problems[i]]\n",
    "    comp_t = comp_t.fillna(float(\"inf\"))\n",
    "    return onlyifsolvedlast(comp_t)\n",
    "\n",
    "df1 = lambda problem: df_agent(problem, \"5mill_C/all.csv\")\n",
    "#df1 = lambda problem: df_agent(problem, \"all_ra_afterfix_15.csv\")\n",
    "\n",
    "df2 = lambda problem: df_agent(problem, \"5mill_RA/all.csv\")\n",
    "#df2 = lambda problem: df_comp(problem, ra_results)\n",
    "\n",
    "for i in range(len(problems)):\n",
    "    \n",
    "    grey = \"#d0e1d4\"\n",
    "    red = \"#ed6a5a\"\n",
    "    blue = \"#008bf8\"\n",
    "    green = \"#08a045\"\n",
    "    green1 = \"#adc178\"\n",
    "    green2 = \"#045c27\"\n",
    "    sns.heatmap(data=get_comp_solved_df(df1(problem), df2(problem)), cmap=[grey, red, blue, green, green1, green2], vmin=0, vmax=5, ax=axs[i], cbar=False)\n",
    "    axs[i].invert_yaxis()\n",
    "    axs[i].set_title(problems[i], fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"experiments/figures/generalization/RA_vs_random.jpg\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for key, time in monolithic_results.items():\n",
    "    problem, n, k = key\n",
    "    df.append({\"problem\": problem, \"n\": n, \"k\": k, \"synthesis time(ms)\": time})\n",
    "df = pd.DataFrame(df)\n",
    "df[\"synthesis time(ms)\"] = df.apply(lambda r: np.nan if r[\"synthesis time(ms)\"] > 10*60*1000 else r[\"synthesis time(ms)\"], axis=1)\n",
    "df_mono = df\n",
    "\n",
    "problems = [\"AT\", \"BW\", \"CM\"]\n",
    "f, axs = plt.subplots(2, len(problems), figsize=(5*len(problems), 12))\n",
    "\n",
    "for i in range(len(problems)):\n",
    "    df_agent = pd.read_csv(\"experiments/results/\"+filename([problems[i], 2, 2])+\"/TB_5mill/all.csv\")\n",
    "    df_agent = fill_df(df_agent, 15)\n",
    "    agent_t = df_agent.pivot(\"n\", \"k\", \"expanded transitions\")\n",
    "    ra_t = ra_results[\"expanded transitions\", problems[i]]\n",
    "    agent_t = agent_t.fillna(float(\"inf\"))\n",
    "    ra_t = ra_t.fillna(float(\"inf\"))\n",
    "    \n",
    "    sns.heatmap(data=agent_t, vmin=0, vmax=100000, ax=axs[0][i], cmap=sns.cm.rocket_r)\n",
    "    sns.heatmap(data=ra_t, vmin=0, vmax=100000, ax=axs[1][i], cmap=sns.cm.rocket_r)\n",
    "    axs[0][i].invert_yaxis()\n",
    "    axs[1][i].invert_yaxis()\n",
    "    axs[0][i].set_title(problems[i], fontsize=30)\n",
    "axs[0][0].set_ylabel(\"Agent\", fontsize=30)\n",
    "axs[1][0].set_ylabel(\"RA\", fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"experiments/figures/test_solved_mono.jpg\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-shannon",
   "metadata": {},
   "source": [
    "# Agent vs RA 15 separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap_trans(df, ax):\n",
    "    dfp = df.pivot(\"n\", \"k\", \"expanded transitions\")\n",
    "    sns.heatmap(data=dfp, cmap=sns.cm.rocket_r, ax=ax, vmin=0, vmax=100000)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "def plot_heatmap_time(df, ax):\n",
    "    dfp = df.pivot(\"n\", \"k\", \"synthesis time(ms)\")\n",
    "    sns.heatmap(data=dfp, cmap=sns.cm.rocket_r, ax=ax, xticklabels=range(1, 16), yticklabels=range(1, 16))\n",
    "    ax.set_ylim(0, 15)\n",
    "    ax.set_xlim(0, 15)\n",
    "\n",
    "problems = [\"AT\", \"TA\", \"BW\", \"TL\", \"DP\"]\n",
    "files = [(\"Agent15.csv\", \"Agent\"), (\"RA15.csv\", \"RA\")]\n",
    "f, axs = plt.subplots(len(files), len(problems), figsize = (5*len(problems), 5*len(files)))\n",
    "\n",
    "\n",
    "for i in range(len(files)):\n",
    "    file, name = files[i]\n",
    "    for j in range(len(problems)):\n",
    "        df = pd.read_csv(\"experiments/results 25 mar/\"+filename([problems[j], 2, 2])+\"/\"+file)\n",
    "        plot_heatmap_time(df, ax=axs[i][j])\n",
    "    axs[i][0].set_ylabel(files[i][1], fontsize=30)\n",
    "for i in range(len(problems)):\n",
    "    axs[0][i].set_title(problems[i], fontsize=24)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"experiments/figures/test_all_time.jpg\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-colombia",
   "metadata": {},
   "source": [
    "# Eta y epsilon (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for problem, n, k in [(\"AT\", 2, 2)]:\n",
    "    for eta in [1e-3, 1e-4, 1e-5, 1e-6]:\n",
    "        for eps in [0.05, 0.1]:\n",
    "            for it in range(2):\n",
    "                df.append(pd.read_csv(\"experiments/results 25 mar/\"+filename([problem, n, k])+\"/\"+filename([\"eta\", eta, it, eps])+\".csv\"))\n",
    "                df[-1][\"eta\"] = eta\n",
    "                df[-1][\"it\"] = it\n",
    "                df[-1][\"eps\"] = eps\n",
    "df = pd.concat(df, ignore_index=True)\n",
    "df_preprocess(df, 500)\n",
    "\n",
    "def plot_params(eta, eps):\n",
    "    y_axis = \"expanded transitions / total\"\n",
    "    dfplot = df.loc[(df[\"eta\"]==eta) & (df[\"eps\"]==eps)]\n",
    "    #dfplot = dfplot.loc[dfplot[\"it\"] == 1]\n",
    "    \n",
    "    plot_ra_expanded_transitions(\"AT\", 2, 2, norm=True, color=\"r\")\n",
    "    plot_ra_expanded_transitions(\"AT\", 3, 3, norm=True, color=\"b\")\n",
    "    \n",
    "    sns.lineplot(data=dfplot, x=\"rounded training time\", y=y_axis, hue=\"instance\", ci=None, palette=\"Set1\")\n",
    "    plt.title((eta, eps))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_params_comparison(n, k):\n",
    "    y_axis = \"expanded transitions\"\n",
    "    dfplot = df.loc[(df[\"n\"]==n) & (df[\"eta\"]<=1e-4)]\n",
    "    #dfplot = dfplot.loc[dfplot[\"it\"] == 1]\n",
    "    \n",
    "    plot_ra_expanded_transitions(\"AT\", n, k, norm=False, color=\"black\")\n",
    "    \n",
    "    \n",
    "    sns.lineplot(data=dfplot, x=\"rounded training time\", y=y_axis, hue=\"eta\", ci=None, palette=\"Set1\")\n",
    "    plt.title((eta, eps))\n",
    "    plt.show()\n",
    "\n",
    "#plot_params(1e-5, 0.05)\n",
    "#plot_params(1e-6, 0.05)\n",
    "#plot_params(1e-5, 0.1)\n",
    "#plot_params(1e-6, 0.1)\n",
    "#plot_params(1e-5, 0.05)\n",
    "\n",
    "plot_params_comparison(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-incident",
   "metadata": {},
   "source": [
    "# Feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "states_file = \"states_context.pkl\"\n",
    "dfs = []\n",
    "problems = [\"AT\", \"BW\", \"DP\", \"TA\", \"TL\", \"CM\"]\n",
    "for problem in problems:\n",
    "    features = feature_names({\"ra feature\": True, \"context features\": True}, problem)\n",
    "    df = {name: [] for name in features}\n",
    "    with open(\"experiments/results/\"+filename([problem, n, n])+\"/\"+states_file, \"rb\") as f:\n",
    "        states = pickle.load(f)\n",
    "    for s in states:\n",
    "        for a in s:\n",
    "            for i in range(len(features)):\n",
    "                df[features[i]].append(a[i])\n",
    "    df = pd.DataFrame(df)\n",
    "    df[\"problem\"] = problem\n",
    "    dfs.append(df)\n",
    "    print(problem, df[\"in open\"].sum(), df[\"in open\"].sum() / df.shape[0])\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((df[\"action controllable\"] > 0.5) & (df[\"ra type best\"] > 0.75)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = \"TL\"\n",
    "dfp = df.loc[df[\"problem\"] == problem]\n",
    "features = feature_names({\"ra feature\": True, \"context features\": True}, problem)\n",
    "for name in features:\n",
    "    dfp[name].plot(kind='hist');\n",
    "    plt.title((name, problem))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generalization(df, x=\"training time\"):\n",
    "    plot_ra_expanded_transitions(df[\"problem\"].iloc[0], 2, 2, norm=True, color=\"r\", label=None)\n",
    "    plot_ra_expanded_transitions(df[\"problem\"].iloc[0], 3, 3, norm=True, color=\"b\", label=None)\n",
    "    sns.lineplot(data=df, x=x, y=\"expanded transitions / total\", hue=\"instance\", palette=[\"r\", \"b\"], ci=None)\n",
    "    plt.xlabel(x, fontsize=14)\n",
    "    plt.ylabel(\"expanded transitions / total\", fontsize=14)\n",
    "    plt.title(\" \".join([problem, str(n), str(k)]))\n",
    "    plt.ylim((0, 1))\n",
    "    plt.tight_layout()\n",
    "\n",
    "def plot_3_3(df):\n",
    "    plot_ra_expanded_transitions(df[\"problem\"].iloc[0], 3, 3, norm=True, color=\"b\", label=None)\n",
    "    sns.lineplot(data=df.loc[df[\"n\"] == 3], x=\"rounded training time\", y=\"expanded transitions / total\", color=\"b\", ci=None)\n",
    "    plt.xlabel(\"training time\", fontsize=14)\n",
    "    plt.ylabel(\"expanded transitions / total\", fontsize=14)\n",
    "    #plt.title(\" \".join([problem, str(n), str(k)]))\n",
    "    plt.ylim((0, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"experiments/figures/trans_3_3/\"+filename([problem, n, k, \"trans_3_3\"])+\".png\", dpi=200)\n",
    "    plt.show()    \n",
    "\n",
    "def plot_2_2(df):\n",
    "    plot_ra_expanded_transitions(df[\"problem\"].iloc[0], 2, 2, norm=True, color=\"r\", label=None)\n",
    "    sns.lineplot(data=df.loc[df[\"n\"] == 2], x=\"rounded training time\", y=\"expanded transitions / total\", color=\"r\", ci=None)\n",
    "    plt.xlabel(\"training time\", fontsize=14)\n",
    "    plt.ylabel(\"expanded transitions / total\", fontsize=14)\n",
    "    #plt.title(\" \".join([problem, str(n), str(k)]))\n",
    "    plt.ylim((0, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"experiments/figures/trans_2_2/\"+filename([problem, n, k, \"trans_2_2\"])+\".png\", dpi=200)\n",
    "    plt.show()  \n",
    "    \n",
    "def plot_q(df):\n",
    "    df2_2 = df.loc[df[\"n\"] == 2]\n",
    "    sns.lineplot(data=df2_2, x=\"rounded training time\", y=\"expanded transitions\", label=\"test\")\n",
    "    sns.lineplot(data=df2_2, x=\"rounded training time\", y=\"avg q\", label=\"avg q\")\n",
    "    plt.xlabel(\"training time\")\n",
    "    plt.title(\" \".join([problem, str(n), str(k)]))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"experiments/figures/q/\"+filename([problem, n, k, \"q\"])+\".jpg\", dpi=200)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_features(df, features, ra_feature, dir=None):\n",
    "    df2_2 = df.loc[df[\"n\"] == 2]\n",
    "    fig = plt.figure(figsize=(10, 5), dpi=200)\n",
    "    for feature in features:\n",
    "        df2_2[feature] = -df2_2[feature]\n",
    "        sns.lineplot(data=df2_2, x=\"rounded training time\", y=feature, label=feature)\n",
    "    \n",
    "    plt.xlabel(\"training time\")\n",
    "    plt.title((problem, n, k, ra_feature))\n",
    "    plt.tight_layout()\n",
    "    if dir is not None:\n",
    "        plt.savefig(\"experiments/figures/\"+dir+\"/features evolution/\"+filename([problem, n, k, ra_feature])+\".jpg\", dpi=200)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_features_best(df, ra_feature, n, dir=None, last=False):\n",
    "    names = feature_names(ra_feature)\n",
    "    df = df.loc[df[\"n\"] == n]\n",
    "    if last:\n",
    "        idx = df[\"idx\"].max()\n",
    "    else:\n",
    "        idx = df.loc[df[\"expanded transitions\"] == df[\"expanded transitions\"].min()][\"idx\"].iloc[0]\n",
    "    features = dict(-df.loc[df[\"idx\"] == idx].iloc[0][names])\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 6), dpi=200)\n",
    "    plt.bar(x=features.keys(), height=features.values(), width=0.3)\n",
    "    plt.xticks(ha='right', rotation=55, fontsize=10)\n",
    "    plt.title((problem, n, n, \"idx = \"+str(idx)))\n",
    "    plt.tight_layout()\n",
    "    if dir is not None:\n",
    "        plt.savefig(\"experiments/figures/\"+dir+\"/best_features/\"+filename([problem, n, n, ra_feature])+\".jpg\", dpi=200)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_comparison(df1, df2, n, x, y, dir=None):\n",
    "    df = pd.concat([df1, df2], ignore_index=True)\n",
    "    \n",
    "    if y == \"expanded transitions / total\":\n",
    "        plot_ra_expanded_transitions(df[\"problem\"].iloc[0], n, n, norm=True, color=\"r\", label=None)\n",
    "    elif y == \"expanded transitions\":\n",
    "        plot_ra_expanded_transitions(df[\"problem\"].iloc[0], n, n, norm=False, color=\"r\", label=None)\n",
    "    \n",
    "    sns.lineplot(data=df.loc[df[\"n\"] == n], x=x, y=y, hue=\"features\", color=\"r\", ci=None)\n",
    "    \n",
    "    plt.xlabel(\"training time\")\n",
    "    plt.title(\" \".join([problem, str(n), str(n)]))\n",
    "    plt.tight_layout()\n",
    "    if dir is not None:\n",
    "        plt.savefig(\"experiments/figures/\"+dir+\"/\"+filename([problem, n, n, \"comp\"])+\".jpg\", dpi=200)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'descend.0.0', 'air.crash.1', 'land.0', 'requestLand.0', 'requestLand.1', 'air.crash.0', 'descend.1.0', 'control.all', 'approach.0', 'descend.0.1', 'extendFlight.1', 'land.1', 'descend.1.1', 'extendFlight.0', 'approach.1'}\n",
    "\n",
    "def simplify(l):\n",
    "    return \"\".join([c for c in l if c.isalpha()])\n",
    "\n",
    "for label in labels:\n",
    "    print(label, simplify(label))\n",
    "    \n",
    "print(labels)\n",
    "print({simplify(l) for l in labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-chosen",
   "metadata": {},
   "source": [
    "## Analyzing nn weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-words",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import numpy_helper\n",
    "\n",
    "weights = []\n",
    "for idx in range(100):\n",
    "    onnx_model = onnx.load(\"experiments/results/AT_3_3/5mill/\" + str(idx)+\".onnx\")\n",
    "    INTIALIZERS  = onnx_model.graph.initializer\n",
    "    onnx_weights = {}\n",
    "    for initializer in INTIALIZERS:\n",
    "        W = numpy_helper.to_array(initializer)\n",
    "        onnx_weights[initializer.name] = W\n",
    "    w = onnx_weights[\"coefficient\"]\n",
    "    if True:\n",
    "        for key, value in onnx_weights.items():\n",
    "            if key == \"coefficient1\":\n",
    "                print(key, value.min(), value.max())\n",
    "    for feature in range(w.shape[0]):\n",
    "        for node in range(w.shape[1]):\n",
    "            weights.append({\"t\": idx, \"val\": w[feature, node], \"feature\": feature, \"node\": node})\n",
    "    \n",
    "weights = pd.DataFrame(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in range(23):\n",
    "    print(feature_names({\"ra feature\": True}, \"AT\")[feature])\n",
    "    df = weights.loc[weights[\"feature\"] == feature]\n",
    "    sns.lineplot(data=df, x=\"t\", y=\"val\", hue=\"node\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
